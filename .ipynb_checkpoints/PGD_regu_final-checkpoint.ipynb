{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os  \n",
    "import numpy as np\n",
    "from scipy import *\n",
    "from numpy import dot, multiply, diag, power, pi, exp, sin, cos, cosh, tanh, real, imag\n",
    "from numpy.linalg import inv, eig, pinv,norm\n",
    "from scipy.linalg import svd, svdvals \n",
    "import scipy.io as sio  \n",
    "import re  \n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import torch \n",
    "from torch.autograd import Variable\n",
    "from torch.optim import Adam, SGD   \n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "from utility import *\n",
    "from model import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters\n",
    "savename = 'PGD_regu_test'  \n",
    "n_class =87\n",
    "dim_input = 1\n",
    "# parameters for CNN \n",
    "patience = 30  \n",
    "gamma = 0.1\n",
    "batch_size =70\n",
    "display_step = 100  \n",
    "num_bus =68 \n",
    "learning_rate = 0.01               \n",
    "rootPath =  './data'\n",
    "trainName = 'train_data.mat'  \n",
    "testName = 'testing_sigPQ_perturb_1' \n",
    "scenario = 1 # choose 1 or 2 denoting the two kinds of testing data in the corresponding scenario \n",
    "model_dir  = './saved_model' \n",
    "epsilon = 0.005\n",
    "k = 7\n",
    "alpha = 0.01 \n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu' \n",
    "weight_decay = 5e-5\n",
    "epochs =800  \n",
    "dim_input = 1 \n",
    "dim_hidden = [4,8,8,8]\n",
    "nclass = 87\n",
    "seed = 1 \n",
    "early_stop = False\n",
    "lam  = 0.1  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "data = sio.loadmat(os.path.join(rootPath, trainName))\n",
    "linedata, Y,  line_neib = loadline(rootPath  ) \n",
    "Y_ri = np.r_[np.c_[Y.real, -Y.imag], np.c_[ Y.imag, Y.real ]].T \n",
    "w = choose_w(linedata,2)  \n",
    "train_x,    train_labels, train_num  = load_all_data_VI(w,rootPath, trainName ) \n",
    "cur_up_limit, cur_down_limit = current_dist(rootPath) \n",
    "vol_up_limit, vol_down_limit = vol_dist(rootPath) \n",
    "up_limit = epsilon * np.r_[vol_up_limit, cur_up_limit]\n",
    "down_limit = epsilon *np.r_[vol_down_limit, cur_down_limit]\n",
    "up_limit = convert_shape(up_limit, batch_size)\n",
    "down_limit = convert_shape(down_limit, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(seed, dim_input, dim_hidden, up_limit, down_limit, batch_size, step_size, k):\n",
    "    np.random.seed( seed)\n",
    "    torch.manual_seed( seed) \n",
    "    \n",
    "    model = Net(dim_input, dim_hidden, nclass) \n",
    "    model.apply(weights_init) \n",
    "    model.train()\n",
    "    optimizer = Adam(model.parameters(), lr=learning_rate, weight_decay = weight_decay)\n",
    "    criterion = CrossEntropyLoss()   \n",
    "    pre_robust_acc = 0. \n",
    "    x_train, y_train = Variable(train_x)  , Variable(train_labels) \n",
    "    train_best = float('Inf') \n",
    "    train_loss_list= [] \n",
    "    for epoch in range( epochs):  \n",
    "        train_loss = 0\n",
    "        train_acc = 0\n",
    "        train_n = 0  \n",
    "        for i in range(int(train_x.shape[0] / batch_size)):\n",
    "            id_train = np.random.choice(train_x.shape[0], batch_size, replace= False) \n",
    "            model.eval()\n",
    "            batch_size, _, size_U, _ = x_train[id_train].shape \n",
    "            delta = torch.randn((batch_size, 1, 2*size_U, 1)).detach()\n",
    "            delta = torch.min(torch.max(delta,   down_limit),   up_limit) \n",
    "            for _ in range(k): \n",
    "                delta.requires_grad_() \n",
    "                delta_U = delta[:, 0, :size_U, 0]\n",
    "                delta_I = delta[:, 0, size_U:,0]  \n",
    "                output = model(x_train[id_train] +    delta[:, :, :size_U, :] )  \n",
    "                loss = F.cross_entropy(output, y_train[id_train], size_average = False )\\\n",
    "                - gamma*torch.nn.functional.l1_loss\\\n",
    "                ( (torch.matmul( delta_U , torch.FloatTensor(Y_ri))   ), (delta_I), size_average = False)\n",
    "                loss.backward()\n",
    "                grad = delta.grad.detach()\n",
    "                delta = delta.detach() + step_size * torch.sign(grad.detach()) \n",
    "                delta = torch.min(torch.max(delta,   down_limit),   up_limit)  \n",
    "            model.train() \n",
    "            x_adv = x_train[id_train].detach()  + delta[:, :, :size_U, :].detach()\n",
    "            output = model(x_adv)\n",
    "            loss = criterion(output, y_train[id_train])\n",
    "            optimizer.zero_grad() \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item()  #* y_train[id_train].size(0)\n",
    "            train_acc  = (output.max(1)[1] == y_train[id_train]).sum().item() *100/np.shape(id_train)[0]  \n",
    "            train_n += y_train[id_train].size(0)\n",
    "            if epoch%5 == 0: \n",
    "                print('Training Epoch: {}, [{}/{}, {:.0f}%], loss is {:.6f}'\\\n",
    "                      .format(epoch  , i * batch_size, train_x.shape[0],  train_acc  , train_loss  )) \n",
    "                if train_loss < train_best:\n",
    "                    print('Best Epoch is', epoch)\n",
    "                    train_best = train_loss \n",
    "                    torch.save(model.state_dict(), os.path.join(model_dir, savename+'.pt'))\n",
    "                    torch.save(optimizer.state_dict(), os.path.join(model_dir, savename+'.tar')) \n",
    "            train_loss_list.append(loss.item())  \n",
    "        if not early_stop:\n",
    "            best_state_dict = model.state_dict()    \n",
    "    plt.plot(train_loss_list)\n",
    "    return train_loss_list , train_best \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch: 0, [0/560, 0%], loss is 4.601176\n",
      "Best Epoch is 0\n",
      "Training Epoch: 0, [70/560, 3%], loss is 9.094516\n",
      "Training Epoch: 0, [140/560, 4%], loss is 13.532919\n",
      "Training Epoch: 0, [210/560, 3%], loss is 17.826720\n",
      "Training Epoch: 0, [280/560, 4%], loss is 22.095142\n",
      "Training Epoch: 0, [350/560, 3%], loss is 26.341271\n",
      "Training Epoch: 0, [420/560, 3%], loss is 30.399306\n",
      "Training Epoch: 0, [490/560, 9%], loss is 34.384307\n",
      "Training Epoch: 5, [0/560, 33%], loss is 2.479852\n",
      "Best Epoch is 5\n",
      "Training Epoch: 5, [70/560, 39%], loss is 4.773050\n",
      "Training Epoch: 5, [140/560, 43%], loss is 6.994965\n",
      "Training Epoch: 5, [210/560, 44%], loss is 9.161483\n",
      "Training Epoch: 5, [280/560, 40%], loss is 11.447414\n",
      "Training Epoch: 5, [350/560, 53%], loss is 13.373450\n",
      "Training Epoch: 5, [420/560, 40%], loss is 15.423497\n",
      "Training Epoch: 5, [490/560, 41%], loss is 17.539521\n",
      "Training Epoch: 10, [0/560, 57%], loss is 1.362743\n",
      "Best Epoch is 10\n",
      "Training Epoch: 10, [70/560, 61%], loss is 2.598891\n",
      "Training Epoch: 10, [140/560, 67%], loss is 3.675929\n",
      "Training Epoch: 10, [210/560, 60%], loss is 4.900359\n",
      "Training Epoch: 10, [280/560, 74%], loss is 5.995838\n",
      "Training Epoch: 10, [350/560, 61%], loss is 7.158916\n",
      "Training Epoch: 10, [420/560, 70%], loss is 8.198520\n",
      "Training Epoch: 10, [490/560, 71%], loss is 9.207685\n",
      "Training Epoch: 15, [0/560, 76%], loss is 0.868113\n",
      "Best Epoch is 15\n",
      "Training Epoch: 15, [70/560, 74%], loss is 1.688546\n",
      "Training Epoch: 15, [140/560, 69%], loss is 2.721297\n",
      "Training Epoch: 15, [210/560, 66%], loss is 3.653694\n",
      "Training Epoch: 15, [280/560, 71%], loss is 4.544824\n",
      "Training Epoch: 15, [350/560, 69%], loss is 5.533330\n",
      "Training Epoch: 15, [420/560, 76%], loss is 6.422247\n",
      "Training Epoch: 15, [490/560, 80%], loss is 7.201017\n",
      "Training Epoch: 20, [0/560, 81%], loss is 0.623766\n",
      "Best Epoch is 20\n",
      "Training Epoch: 20, [70/560, 77%], loss is 1.361310\n",
      "Training Epoch: 20, [140/560, 80%], loss is 2.095424\n",
      "Training Epoch: 20, [210/560, 83%], loss is 2.681594\n",
      "Training Epoch: 20, [280/560, 83%], loss is 3.327060\n",
      "Training Epoch: 20, [350/560, 86%], loss is 3.920448\n",
      "Training Epoch: 20, [420/560, 81%], loss is 4.593249\n",
      "Training Epoch: 20, [490/560, 83%], loss is 5.212857\n",
      "Training Epoch: 25, [0/560, 91%], loss is 0.446511\n",
      "Best Epoch is 25\n",
      "Training Epoch: 25, [70/560, 70%], loss is 1.198698\n",
      "Training Epoch: 25, [140/560, 77%], loss is 1.896067\n",
      "Training Epoch: 25, [210/560, 79%], loss is 2.532608\n",
      "Training Epoch: 25, [280/560, 76%], loss is 3.202279\n",
      "Training Epoch: 25, [350/560, 80%], loss is 3.955794\n",
      "Training Epoch: 25, [420/560, 74%], loss is 4.606596\n",
      "Training Epoch: 25, [490/560, 77%], loss is 5.206616\n",
      "Training Epoch: 30, [0/560, 84%], loss is 0.592068\n",
      "Training Epoch: 30, [70/560, 77%], loss is 1.167159\n",
      "Training Epoch: 30, [140/560, 79%], loss is 1.687902\n",
      "Training Epoch: 30, [210/560, 79%], loss is 2.228291\n",
      "Training Epoch: 30, [280/560, 84%], loss is 2.746777\n",
      "Training Epoch: 30, [350/560, 76%], loss is 3.384414\n",
      "Training Epoch: 30, [420/560, 70%], loss is 4.167511\n",
      "Training Epoch: 30, [490/560, 77%], loss is 4.729922\n",
      "Training Epoch: 35, [0/560, 86%], loss is 0.414164\n",
      "Best Epoch is 35\n",
      "Training Epoch: 35, [70/560, 77%], loss is 1.069606\n",
      "Training Epoch: 35, [140/560, 84%], loss is 1.604249\n",
      "Training Epoch: 35, [210/560, 81%], loss is 2.103106\n",
      "Training Epoch: 35, [280/560, 76%], loss is 2.607554\n",
      "Training Epoch: 35, [350/560, 80%], loss is 3.269744\n",
      "Training Epoch: 35, [420/560, 76%], loss is 3.873768\n",
      "Training Epoch: 35, [490/560, 80%], loss is 4.385812\n",
      "Training Epoch: 40, [0/560, 91%], loss is 0.314912\n",
      "Best Epoch is 40\n",
      "Training Epoch: 40, [70/560, 84%], loss is 0.744420\n",
      "Training Epoch: 40, [140/560, 86%], loss is 1.194821\n",
      "Training Epoch: 40, [210/560, 80%], loss is 1.684776\n",
      "Training Epoch: 40, [280/560, 87%], loss is 2.075150\n",
      "Training Epoch: 40, [350/560, 93%], loss is 2.392245\n",
      "Training Epoch: 40, [420/560, 90%], loss is 2.696585\n",
      "Training Epoch: 40, [490/560, 86%], loss is 3.034915\n",
      "Training Epoch: 45, [0/560, 81%], loss is 0.519180\n",
      "Training Epoch: 45, [70/560, 80%], loss is 1.003275\n",
      "Training Epoch: 45, [140/560, 83%], loss is 1.636495\n",
      "Training Epoch: 45, [210/560, 84%], loss is 2.059413\n",
      "Training Epoch: 45, [280/560, 91%], loss is 2.311604\n",
      "Training Epoch: 45, [350/560, 81%], loss is 2.785118\n",
      "Training Epoch: 45, [420/560, 87%], loss is 3.262085\n",
      "Training Epoch: 45, [490/560, 80%], loss is 3.782941\n",
      "Training Epoch: 50, [0/560, 79%], loss is 0.560245\n",
      "Training Epoch: 50, [70/560, 81%], loss is 1.073457\n",
      "Training Epoch: 50, [140/560, 86%], loss is 1.514420\n",
      "Training Epoch: 50, [210/560, 80%], loss is 2.050045\n",
      "Training Epoch: 50, [280/560, 84%], loss is 2.493352\n",
      "Training Epoch: 50, [350/560, 86%], loss is 2.996395\n",
      "Training Epoch: 50, [420/560, 86%], loss is 3.358366\n",
      "Training Epoch: 50, [490/560, 83%], loss is 3.819893\n",
      "Training Epoch: 55, [0/560, 93%], loss is 0.319885\n",
      "Training Epoch: 55, [70/560, 90%], loss is 0.610199\n",
      "Training Epoch: 55, [140/560, 89%], loss is 0.965043\n",
      "Training Epoch: 55, [210/560, 96%], loss is 1.246563\n",
      "Training Epoch: 55, [280/560, 83%], loss is 1.751288\n",
      "Training Epoch: 55, [350/560, 81%], loss is 2.269322\n",
      "Training Epoch: 55, [420/560, 86%], loss is 2.651314\n",
      "Training Epoch: 55, [490/560, 84%], loss is 3.014402\n",
      "Training Epoch: 60, [0/560, 80%], loss is 0.550649\n",
      "Training Epoch: 60, [70/560, 89%], loss is 0.857583\n",
      "Training Epoch: 60, [140/560, 90%], loss is 1.155124\n",
      "Training Epoch: 60, [210/560, 89%], loss is 1.565975\n",
      "Training Epoch: 60, [280/560, 84%], loss is 2.001570\n",
      "Training Epoch: 60, [350/560, 87%], loss is 2.360337\n",
      "Training Epoch: 60, [420/560, 86%], loss is 2.653409\n",
      "Training Epoch: 60, [490/560, 84%], loss is 3.026621\n",
      "Training Epoch: 65, [0/560, 87%], loss is 0.314369\n",
      "Best Epoch is 65\n",
      "Training Epoch: 65, [70/560, 90%], loss is 0.652770\n",
      "Training Epoch: 65, [140/560, 74%], loss is 1.371265\n",
      "Training Epoch: 65, [210/560, 83%], loss is 1.814612\n",
      "Training Epoch: 65, [280/560, 81%], loss is 2.323326\n",
      "Training Epoch: 65, [350/560, 90%], loss is 2.621308\n",
      "Training Epoch: 65, [420/560, 84%], loss is 3.035504\n",
      "Training Epoch: 65, [490/560, 81%], loss is 3.635301\n",
      "Training Epoch: 70, [0/560, 73%], loss is 0.758633\n",
      "Training Epoch: 70, [70/560, 97%], loss is 0.965203\n",
      "Training Epoch: 70, [140/560, 86%], loss is 1.356426\n",
      "Training Epoch: 70, [210/560, 80%], loss is 1.915384\n",
      "Training Epoch: 70, [280/560, 80%], loss is 2.355051\n",
      "Training Epoch: 70, [350/560, 83%], loss is 2.775730\n",
      "Training Epoch: 70, [420/560, 83%], loss is 3.259274\n",
      "Training Epoch: 70, [490/560, 73%], loss is 3.863914\n",
      "Training Epoch: 75, [0/560, 86%], loss is 0.313022\n",
      "Best Epoch is 75\n",
      "Training Epoch: 75, [70/560, 96%], loss is 0.549324\n",
      "Training Epoch: 75, [140/560, 94%], loss is 0.826586\n",
      "Training Epoch: 75, [210/560, 91%], loss is 1.096476\n",
      "Training Epoch: 75, [280/560, 94%], loss is 1.341292\n",
      "Training Epoch: 75, [350/560, 93%], loss is 1.552842\n",
      "Training Epoch: 75, [420/560, 93%], loss is 1.838773\n",
      "Training Epoch: 75, [490/560, 89%], loss is 2.188644\n",
      "Training Epoch: 80, [0/560, 83%], loss is 0.421272\n",
      "Training Epoch: 80, [70/560, 86%], loss is 0.772078\n",
      "Training Epoch: 80, [140/560, 77%], loss is 1.418368\n",
      "Training Epoch: 80, [210/560, 87%], loss is 1.765537\n",
      "Training Epoch: 80, [280/560, 93%], loss is 2.020491\n",
      "Training Epoch: 80, [350/560, 83%], loss is 2.434980\n",
      "Training Epoch: 80, [420/560, 84%], loss is 2.819919\n",
      "Training Epoch: 80, [490/560, 91%], loss is 3.138178\n",
      "Training Epoch: 85, [0/560, 93%], loss is 0.194732\n",
      "Best Epoch is 85\n",
      "Training Epoch: 85, [70/560, 86%], loss is 0.540238\n",
      "Training Epoch: 85, [140/560, 80%], loss is 0.960672\n",
      "Training Epoch: 85, [210/560, 91%], loss is 1.212063\n",
      "Training Epoch: 85, [280/560, 89%], loss is 1.564304\n",
      "Training Epoch: 85, [350/560, 96%], loss is 1.855100\n",
      "Training Epoch: 85, [420/560, 91%], loss is 2.179366\n",
      "Training Epoch: 85, [490/560, 89%], loss is 2.435487\n",
      "Training Epoch: 90, [0/560, 87%], loss is 0.266955\n",
      "Training Epoch: 90, [70/560, 83%], loss is 0.708437\n",
      "Training Epoch: 90, [140/560, 83%], loss is 1.107037\n",
      "Training Epoch: 90, [210/560, 90%], loss is 1.430647\n",
      "Training Epoch: 90, [280/560, 93%], loss is 1.662896\n",
      "Training Epoch: 90, [350/560, 87%], loss is 1.990865\n",
      "Training Epoch: 90, [420/560, 84%], loss is 2.446621\n",
      "Training Epoch: 90, [490/560, 86%], loss is 2.818537\n",
      "Training Epoch: 95, [0/560, 84%], loss is 0.358016\n",
      "Training Epoch: 95, [70/560, 89%], loss is 0.730000\n",
      "Training Epoch: 95, [140/560, 89%], loss is 1.037057\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch: 95, [210/560, 93%], loss is 1.305849\n",
      "Training Epoch: 95, [280/560, 89%], loss is 1.630116\n",
      "Training Epoch: 95, [350/560, 90%], loss is 2.016837\n",
      "Training Epoch: 95, [420/560, 94%], loss is 2.175394\n",
      "Training Epoch: 95, [490/560, 93%], loss is 2.487713\n",
      "Training Epoch: 100, [0/560, 87%], loss is 0.347997\n",
      "Training Epoch: 100, [70/560, 84%], loss is 0.777391\n",
      "Training Epoch: 100, [140/560, 90%], loss is 1.108390\n",
      "Training Epoch: 100, [210/560, 94%], loss is 1.283901\n",
      "Training Epoch: 100, [280/560, 83%], loss is 1.797235\n",
      "Training Epoch: 100, [350/560, 84%], loss is 2.172142\n",
      "Training Epoch: 100, [420/560, 87%], loss is 2.528275\n",
      "Training Epoch: 100, [490/560, 89%], loss is 2.804524\n",
      "Training Epoch: 105, [0/560, 83%], loss is 0.447395\n",
      "Training Epoch: 105, [70/560, 87%], loss is 0.752128\n",
      "Training Epoch: 105, [140/560, 87%], loss is 1.022023\n",
      "Training Epoch: 105, [210/560, 86%], loss is 1.333490\n",
      "Training Epoch: 105, [280/560, 89%], loss is 1.610326\n",
      "Training Epoch: 105, [350/560, 91%], loss is 1.868347\n",
      "Training Epoch: 105, [420/560, 94%], loss is 2.088348\n",
      "Training Epoch: 105, [490/560, 91%], loss is 2.347465\n",
      "Training Epoch: 110, [0/560, 81%], loss is 0.484871\n",
      "Training Epoch: 110, [70/560, 87%], loss is 0.913950\n",
      "Training Epoch: 110, [140/560, 90%], loss is 1.256928\n",
      "Training Epoch: 110, [210/560, 79%], loss is 1.752049\n",
      "Training Epoch: 110, [280/560, 74%], loss is 2.373922\n",
      "Training Epoch: 110, [350/560, 84%], loss is 2.858326\n",
      "Training Epoch: 110, [420/560, 80%], loss is 3.437228\n",
      "Training Epoch: 110, [490/560, 84%], loss is 3.888139\n",
      "Training Epoch: 115, [0/560, 89%], loss is 0.314601\n",
      "Training Epoch: 115, [70/560, 80%], loss is 0.789319\n",
      "Training Epoch: 115, [140/560, 93%], loss is 1.100760\n",
      "Training Epoch: 115, [210/560, 96%], loss is 1.285697\n",
      "Training Epoch: 115, [280/560, 80%], loss is 1.652288\n",
      "Training Epoch: 115, [350/560, 99%], loss is 1.884636\n",
      "Training Epoch: 115, [420/560, 87%], loss is 2.291110\n",
      "Training Epoch: 115, [490/560, 91%], loss is 2.601078\n",
      "Training Epoch: 120, [0/560, 90%], loss is 0.329019\n",
      "Training Epoch: 120, [70/560, 93%], loss is 0.627747\n",
      "Training Epoch: 120, [140/560, 86%], loss is 1.044208\n",
      "Training Epoch: 120, [210/560, 93%], loss is 1.315548\n",
      "Training Epoch: 120, [280/560, 90%], loss is 1.667905\n",
      "Training Epoch: 120, [350/560, 90%], loss is 1.968373\n",
      "Training Epoch: 120, [420/560, 91%], loss is 2.176775\n",
      "Training Epoch: 120, [490/560, 93%], loss is 2.420058\n",
      "Training Epoch: 125, [0/560, 90%], loss is 0.244324\n",
      "Training Epoch: 125, [70/560, 89%], loss is 0.574304\n",
      "Training Epoch: 125, [140/560, 89%], loss is 0.847888\n",
      "Training Epoch: 125, [210/560, 96%], loss is 1.044791\n",
      "Training Epoch: 125, [280/560, 91%], loss is 1.273333\n",
      "Training Epoch: 125, [350/560, 91%], loss is 1.556761\n",
      "Training Epoch: 125, [420/560, 89%], loss is 1.778251\n",
      "Training Epoch: 125, [490/560, 89%], loss is 2.049046\n",
      "Training Epoch: 130, [0/560, 96%], loss is 0.128421\n",
      "Best Epoch is 130\n",
      "Training Epoch: 130, [70/560, 91%], loss is 0.375055\n",
      "Training Epoch: 130, [140/560, 96%], loss is 0.588305\n",
      "Training Epoch: 130, [210/560, 89%], loss is 0.931365\n",
      "Training Epoch: 130, [280/560, 91%], loss is 1.154775\n",
      "Training Epoch: 130, [350/560, 87%], loss is 1.423295\n",
      "Training Epoch: 130, [420/560, 96%], loss is 1.598034\n",
      "Training Epoch: 130, [490/560, 93%], loss is 1.790100\n",
      "Training Epoch: 135, [0/560, 91%], loss is 0.270284\n",
      "Training Epoch: 135, [70/560, 89%], loss is 0.579315\n",
      "Training Epoch: 135, [140/560, 90%], loss is 0.819263\n",
      "Training Epoch: 135, [210/560, 91%], loss is 1.061697\n",
      "Training Epoch: 135, [280/560, 77%], loss is 1.658296\n",
      "Training Epoch: 135, [350/560, 83%], loss is 1.998509\n",
      "Training Epoch: 135, [420/560, 90%], loss is 2.279128\n",
      "Training Epoch: 135, [490/560, 86%], loss is 2.614013\n",
      "Training Epoch: 140, [0/560, 89%], loss is 0.221951\n",
      "Training Epoch: 140, [70/560, 87%], loss is 0.614305\n",
      "Training Epoch: 140, [140/560, 89%], loss is 0.908573\n",
      "Training Epoch: 140, [210/560, 89%], loss is 1.187774\n",
      "Training Epoch: 140, [280/560, 87%], loss is 1.499997\n",
      "Training Epoch: 140, [350/560, 91%], loss is 1.724613\n",
      "Training Epoch: 140, [420/560, 89%], loss is 2.032372\n",
      "Training Epoch: 140, [490/560, 87%], loss is 2.321638\n",
      "Training Epoch: 145, [0/560, 87%], loss is 0.348872\n",
      "Training Epoch: 145, [70/560, 91%], loss is 0.592503\n",
      "Training Epoch: 145, [140/560, 91%], loss is 0.890256\n",
      "Training Epoch: 145, [210/560, 93%], loss is 1.082269\n",
      "Training Epoch: 145, [280/560, 94%], loss is 1.305021\n",
      "Training Epoch: 145, [350/560, 89%], loss is 1.658256\n",
      "Training Epoch: 145, [420/560, 84%], loss is 2.039678\n",
      "Training Epoch: 145, [490/560, 91%], loss is 2.323888\n",
      "Training Epoch: 150, [0/560, 89%], loss is 0.292173\n",
      "Training Epoch: 150, [70/560, 90%], loss is 0.542740\n",
      "Training Epoch: 150, [140/560, 89%], loss is 0.856900\n",
      "Training Epoch: 150, [210/560, 89%], loss is 1.141439\n",
      "Training Epoch: 150, [280/560, 90%], loss is 1.459288\n",
      "Training Epoch: 150, [350/560, 97%], loss is 1.608826\n",
      "Training Epoch: 150, [420/560, 93%], loss is 1.841847\n",
      "Training Epoch: 150, [490/560, 93%], loss is 2.142984\n",
      "Training Epoch: 155, [0/560, 93%], loss is 0.339897\n",
      "Training Epoch: 155, [70/560, 93%], loss is 0.583288\n",
      "Training Epoch: 155, [140/560, 87%], loss is 0.875258\n",
      "Training Epoch: 155, [210/560, 76%], loss is 1.396094\n",
      "Training Epoch: 155, [280/560, 89%], loss is 1.718521\n",
      "Training Epoch: 155, [350/560, 87%], loss is 2.164291\n",
      "Training Epoch: 155, [420/560, 86%], loss is 2.616995\n",
      "Training Epoch: 155, [490/560, 89%], loss is 2.923207\n",
      "Training Epoch: 160, [0/560, 90%], loss is 0.273288\n",
      "Training Epoch: 160, [70/560, 87%], loss is 0.577203\n",
      "Training Epoch: 160, [140/560, 80%], loss is 0.965970\n",
      "Training Epoch: 160, [210/560, 91%], loss is 1.316754\n",
      "Training Epoch: 160, [280/560, 81%], loss is 1.702314\n",
      "Training Epoch: 160, [350/560, 89%], loss is 2.041095\n",
      "Training Epoch: 160, [420/560, 90%], loss is 2.330771\n",
      "Training Epoch: 160, [490/560, 90%], loss is 2.595908\n",
      "Training Epoch: 165, [0/560, 94%], loss is 0.215481\n",
      "Training Epoch: 165, [70/560, 91%], loss is 0.499927\n",
      "Training Epoch: 165, [140/560, 93%], loss is 0.767878\n",
      "Training Epoch: 165, [210/560, 90%], loss is 1.075863\n",
      "Training Epoch: 165, [280/560, 93%], loss is 1.308413\n",
      "Training Epoch: 165, [350/560, 93%], loss is 1.505221\n",
      "Training Epoch: 165, [420/560, 90%], loss is 1.726636\n",
      "Training Epoch: 165, [490/560, 97%], loss is 1.851218\n",
      "Training Epoch: 170, [0/560, 86%], loss is 0.371279\n",
      "Training Epoch: 170, [70/560, 87%], loss is 0.704485\n",
      "Training Epoch: 170, [140/560, 86%], loss is 1.044602\n",
      "Training Epoch: 170, [210/560, 93%], loss is 1.283918\n",
      "Training Epoch: 170, [280/560, 94%], loss is 1.519729\n",
      "Training Epoch: 170, [350/560, 83%], loss is 2.077710\n",
      "Training Epoch: 170, [420/560, 79%], loss is 2.538475\n",
      "Training Epoch: 170, [490/560, 86%], loss is 2.855227\n",
      "Training Epoch: 175, [0/560, 93%], loss is 0.173352\n",
      "Training Epoch: 175, [70/560, 91%], loss is 0.449989\n",
      "Training Epoch: 175, [140/560, 93%], loss is 0.626760\n",
      "Training Epoch: 175, [210/560, 97%], loss is 0.763247\n",
      "Training Epoch: 175, [280/560, 93%], loss is 1.010784\n",
      "Training Epoch: 175, [350/560, 91%], loss is 1.176882\n",
      "Training Epoch: 175, [420/560, 81%], loss is 1.596309\n",
      "Training Epoch: 175, [490/560, 89%], loss is 1.838796\n",
      "Training Epoch: 180, [0/560, 94%], loss is 0.153302\n",
      "Training Epoch: 180, [70/560, 89%], loss is 0.451565\n",
      "Training Epoch: 180, [140/560, 87%], loss is 0.754472\n",
      "Training Epoch: 180, [210/560, 89%], loss is 1.106245\n",
      "Training Epoch: 180, [280/560, 86%], loss is 1.630056\n",
      "Training Epoch: 180, [350/560, 91%], loss is 1.813926\n",
      "Training Epoch: 180, [420/560, 90%], loss is 2.072369\n",
      "Training Epoch: 180, [490/560, 91%], loss is 2.313903\n",
      "Training Epoch: 185, [0/560, 91%], loss is 0.267713\n",
      "Training Epoch: 185, [70/560, 96%], loss is 0.441674\n",
      "Training Epoch: 185, [140/560, 89%], loss is 0.750664\n",
      "Training Epoch: 185, [210/560, 81%], loss is 1.223796\n",
      "Training Epoch: 185, [280/560, 86%], loss is 1.685672\n",
      "Training Epoch: 185, [350/560, 86%], loss is 2.060533\n",
      "Training Epoch: 185, [420/560, 91%], loss is 2.348924\n",
      "Training Epoch: 185, [490/560, 87%], loss is 2.670294\n",
      "Training Epoch: 190, [0/560, 84%], loss is 0.380501\n",
      "Training Epoch: 190, [70/560, 91%], loss is 0.630785\n",
      "Training Epoch: 190, [140/560, 80%], loss is 1.139160\n",
      "Training Epoch: 190, [210/560, 87%], loss is 1.448164\n",
      "Training Epoch: 190, [280/560, 91%], loss is 1.710653\n",
      "Training Epoch: 190, [350/560, 90%], loss is 1.944246\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch: 190, [420/560, 90%], loss is 2.277195\n",
      "Training Epoch: 190, [490/560, 89%], loss is 2.608908\n",
      "Training Epoch: 195, [0/560, 84%], loss is 0.358196\n",
      "Training Epoch: 195, [70/560, 93%], loss is 0.629723\n",
      "Training Epoch: 195, [140/560, 89%], loss is 0.990233\n",
      "Training Epoch: 195, [210/560, 93%], loss is 1.198888\n",
      "Training Epoch: 195, [280/560, 86%], loss is 1.562058\n",
      "Training Epoch: 195, [350/560, 90%], loss is 1.848939\n",
      "Training Epoch: 195, [420/560, 91%], loss is 2.127327\n",
      "Training Epoch: 195, [490/560, 84%], loss is 2.522222\n",
      "Training Epoch: 200, [0/560, 93%], loss is 0.240352\n",
      "Training Epoch: 200, [70/560, 90%], loss is 0.529191\n",
      "Training Epoch: 200, [140/560, 97%], loss is 0.723074\n",
      "Training Epoch: 200, [210/560, 91%], loss is 0.910237\n",
      "Training Epoch: 200, [280/560, 89%], loss is 1.274455\n",
      "Training Epoch: 200, [350/560, 91%], loss is 1.510691\n",
      "Training Epoch: 200, [420/560, 89%], loss is 1.753767\n",
      "Training Epoch: 200, [490/560, 91%], loss is 1.977586\n",
      "Training Epoch: 205, [0/560, 80%], loss is 0.378871\n",
      "Training Epoch: 205, [70/560, 87%], loss is 0.676513\n",
      "Training Epoch: 205, [140/560, 94%], loss is 0.889039\n",
      "Training Epoch: 205, [210/560, 91%], loss is 1.190173\n",
      "Training Epoch: 205, [280/560, 94%], loss is 1.375717\n",
      "Training Epoch: 205, [350/560, 90%], loss is 1.673786\n",
      "Training Epoch: 205, [420/560, 91%], loss is 1.931269\n",
      "Training Epoch: 205, [490/560, 90%], loss is 2.213413\n",
      "Training Epoch: 210, [0/560, 91%], loss is 0.210242\n",
      "Training Epoch: 210, [70/560, 89%], loss is 0.485061\n",
      "Training Epoch: 210, [140/560, 91%], loss is 0.714811\n",
      "Training Epoch: 210, [210/560, 94%], loss is 0.861902\n",
      "Training Epoch: 210, [280/560, 93%], loss is 1.081021\n",
      "Training Epoch: 210, [350/560, 94%], loss is 1.272411\n",
      "Training Epoch: 210, [420/560, 91%], loss is 1.486881\n",
      "Training Epoch: 210, [490/560, 91%], loss is 1.759175\n",
      "Training Epoch: 215, [0/560, 89%], loss is 0.328693\n",
      "Training Epoch: 215, [70/560, 89%], loss is 0.699892\n",
      "Training Epoch: 215, [140/560, 90%], loss is 0.985624\n",
      "Training Epoch: 215, [210/560, 90%], loss is 1.332841\n",
      "Training Epoch: 215, [280/560, 93%], loss is 1.690621\n",
      "Training Epoch: 215, [350/560, 99%], loss is 1.790791\n",
      "Training Epoch: 215, [420/560, 84%], loss is 2.150286\n",
      "Training Epoch: 215, [490/560, 87%], loss is 2.409368\n",
      "Training Epoch: 220, [0/560, 86%], loss is 0.390367\n",
      "Training Epoch: 220, [70/560, 94%], loss is 0.587369\n",
      "Training Epoch: 220, [140/560, 89%], loss is 0.910598\n",
      "Training Epoch: 220, [210/560, 83%], loss is 1.318376\n",
      "Training Epoch: 220, [280/560, 84%], loss is 1.750461\n",
      "Training Epoch: 220, [350/560, 86%], loss is 2.056111\n",
      "Training Epoch: 220, [420/560, 84%], loss is 2.434685\n",
      "Training Epoch: 220, [490/560, 86%], loss is 2.702549\n",
      "Training Epoch: 225, [0/560, 94%], loss is 0.130753\n",
      "Training Epoch: 225, [70/560, 97%], loss is 0.315501\n",
      "Training Epoch: 225, [140/560, 87%], loss is 0.583376\n",
      "Training Epoch: 225, [210/560, 96%], loss is 0.744257\n",
      "Training Epoch: 225, [280/560, 91%], loss is 0.962000\n",
      "Training Epoch: 225, [350/560, 89%], loss is 1.238500\n",
      "Training Epoch: 225, [420/560, 94%], loss is 1.397014\n",
      "Training Epoch: 225, [490/560, 89%], loss is 1.586740\n",
      "Training Epoch: 230, [0/560, 91%], loss is 0.210107\n",
      "Training Epoch: 230, [70/560, 93%], loss is 0.347155\n",
      "Training Epoch: 230, [140/560, 89%], loss is 0.661698\n",
      "Training Epoch: 230, [210/560, 89%], loss is 0.970098\n",
      "Training Epoch: 230, [280/560, 94%], loss is 1.160570\n",
      "Training Epoch: 230, [350/560, 89%], loss is 1.479587\n",
      "Training Epoch: 230, [420/560, 86%], loss is 1.819525\n",
      "Training Epoch: 230, [490/560, 87%], loss is 2.092222\n",
      "Training Epoch: 235, [0/560, 94%], loss is 0.137416\n",
      "Training Epoch: 235, [70/560, 93%], loss is 0.348084\n",
      "Training Epoch: 235, [140/560, 93%], loss is 0.501792\n",
      "Training Epoch: 235, [210/560, 96%], loss is 0.617984\n",
      "Training Epoch: 235, [280/560, 90%], loss is 0.848264\n",
      "Training Epoch: 235, [350/560, 89%], loss is 1.070685\n",
      "Training Epoch: 235, [420/560, 94%], loss is 1.296212\n",
      "Training Epoch: 235, [490/560, 89%], loss is 1.551441\n",
      "Training Epoch: 240, [0/560, 89%], loss is 0.233251\n",
      "Training Epoch: 240, [70/560, 86%], loss is 0.670822\n",
      "Training Epoch: 240, [140/560, 87%], loss is 0.981813\n",
      "Training Epoch: 240, [210/560, 93%], loss is 1.198410\n",
      "Training Epoch: 240, [280/560, 91%], loss is 1.452789\n",
      "Training Epoch: 240, [350/560, 90%], loss is 1.680315\n",
      "Training Epoch: 240, [420/560, 87%], loss is 2.019885\n",
      "Training Epoch: 240, [490/560, 91%], loss is 2.191120\n",
      "Training Epoch: 245, [0/560, 97%], loss is 0.123296\n",
      "Best Epoch is 245\n",
      "Training Epoch: 245, [70/560, 96%], loss is 0.329970\n",
      "Training Epoch: 245, [140/560, 94%], loss is 0.540082\n",
      "Training Epoch: 245, [210/560, 89%], loss is 0.824105\n",
      "Training Epoch: 245, [280/560, 93%], loss is 1.035903\n",
      "Training Epoch: 245, [350/560, 90%], loss is 1.323332\n",
      "Training Epoch: 245, [420/560, 94%], loss is 1.530132\n",
      "Training Epoch: 245, [490/560, 90%], loss is 1.767677\n",
      "Training Epoch: 250, [0/560, 94%], loss is 0.167350\n",
      "Training Epoch: 250, [70/560, 87%], loss is 0.519721\n",
      "Training Epoch: 250, [140/560, 84%], loss is 0.900001\n",
      "Training Epoch: 250, [210/560, 93%], loss is 1.131519\n",
      "Training Epoch: 250, [280/560, 96%], loss is 1.297219\n",
      "Training Epoch: 250, [350/560, 87%], loss is 1.702214\n",
      "Training Epoch: 250, [420/560, 90%], loss is 1.958454\n",
      "Training Epoch: 250, [490/560, 87%], loss is 2.392215\n",
      "Training Epoch: 255, [0/560, 87%], loss is 0.346854\n",
      "Training Epoch: 255, [70/560, 90%], loss is 0.605180\n",
      "Training Epoch: 255, [140/560, 89%], loss is 0.933263\n",
      "Training Epoch: 255, [210/560, 90%], loss is 1.146662\n",
      "Training Epoch: 255, [280/560, 86%], loss is 1.521171\n",
      "Training Epoch: 255, [350/560, 76%], loss is 2.149744\n",
      "Training Epoch: 255, [420/560, 90%], loss is 2.480186\n",
      "Training Epoch: 255, [490/560, 90%], loss is 2.791499\n",
      "Training Epoch: 260, [0/560, 93%], loss is 0.288129\n",
      "Training Epoch: 260, [70/560, 87%], loss is 0.609666\n",
      "Training Epoch: 260, [140/560, 90%], loss is 0.911287\n",
      "Training Epoch: 260, [210/560, 90%], loss is 1.199658\n",
      "Training Epoch: 260, [280/560, 87%], loss is 1.509138\n",
      "Training Epoch: 260, [350/560, 84%], loss is 1.880128\n",
      "Training Epoch: 260, [420/560, 84%], loss is 2.193221\n",
      "Training Epoch: 260, [490/560, 89%], loss is 2.456310\n",
      "Training Epoch: 265, [0/560, 93%], loss is 0.233668\n",
      "Training Epoch: 265, [70/560, 89%], loss is 0.631041\n",
      "Training Epoch: 265, [140/560, 91%], loss is 0.865705\n",
      "Training Epoch: 265, [210/560, 93%], loss is 1.028223\n",
      "Training Epoch: 265, [280/560, 97%], loss is 1.150275\n",
      "Training Epoch: 265, [350/560, 97%], loss is 1.311534\n",
      "Training Epoch: 265, [420/560, 93%], loss is 1.580512\n",
      "Training Epoch: 265, [490/560, 96%], loss is 1.707958\n",
      "Training Epoch: 270, [0/560, 89%], loss is 0.476429\n",
      "Training Epoch: 270, [70/560, 90%], loss is 1.058665\n",
      "Training Epoch: 270, [140/560, 87%], loss is 1.454374\n",
      "Training Epoch: 270, [210/560, 90%], loss is 1.784024\n",
      "Training Epoch: 270, [280/560, 91%], loss is 2.020102\n",
      "Training Epoch: 270, [350/560, 83%], loss is 2.372273\n",
      "Training Epoch: 270, [420/560, 87%], loss is 2.716162\n",
      "Training Epoch: 270, [490/560, 90%], loss is 3.063677\n",
      "Training Epoch: 275, [0/560, 89%], loss is 0.296727\n",
      "Training Epoch: 275, [70/560, 84%], loss is 0.572836\n",
      "Training Epoch: 275, [140/560, 94%], loss is 0.712321\n",
      "Training Epoch: 275, [210/560, 91%], loss is 0.992369\n",
      "Training Epoch: 275, [280/560, 91%], loss is 1.278541\n",
      "Training Epoch: 275, [350/560, 84%], loss is 1.671182\n",
      "Training Epoch: 275, [420/560, 90%], loss is 1.975401\n",
      "Training Epoch: 275, [490/560, 93%], loss is 2.171493\n",
      "Training Epoch: 280, [0/560, 96%], loss is 0.152543\n",
      "Training Epoch: 280, [70/560, 93%], loss is 0.343946\n",
      "Training Epoch: 280, [140/560, 93%], loss is 0.541673\n",
      "Training Epoch: 280, [210/560, 91%], loss is 0.754983\n",
      "Training Epoch: 280, [280/560, 96%], loss is 0.874287\n",
      "Training Epoch: 280, [350/560, 93%], loss is 1.080139\n",
      "Training Epoch: 280, [420/560, 90%], loss is 1.253125\n",
      "Training Epoch: 280, [490/560, 90%], loss is 1.490834\n",
      "Training Epoch: 285, [0/560, 93%], loss is 0.198576\n",
      "Training Epoch: 285, [70/560, 90%], loss is 0.549213\n",
      "Training Epoch: 285, [140/560, 87%], loss is 0.866026\n",
      "Training Epoch: 285, [210/560, 87%], loss is 1.093488\n",
      "Training Epoch: 285, [280/560, 99%], loss is 1.178296\n",
      "Training Epoch: 285, [350/560, 96%], loss is 1.276293\n",
      "Training Epoch: 285, [420/560, 89%], loss is 1.521699\n",
      "Training Epoch: 285, [490/560, 94%], loss is 1.679943\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch: 290, [0/560, 91%], loss is 0.231779\n",
      "Training Epoch: 290, [70/560, 94%], loss is 0.389930\n",
      "Training Epoch: 290, [140/560, 89%], loss is 0.772437\n",
      "Training Epoch: 290, [210/560, 89%], loss is 1.014020\n",
      "Training Epoch: 290, [280/560, 89%], loss is 1.258438\n",
      "Training Epoch: 290, [350/560, 97%], loss is 1.363312\n",
      "Training Epoch: 290, [420/560, 91%], loss is 1.660851\n",
      "Training Epoch: 290, [490/560, 90%], loss is 1.982271\n",
      "Training Epoch: 295, [0/560, 90%], loss is 0.254792\n",
      "Training Epoch: 295, [70/560, 91%], loss is 0.476457\n",
      "Training Epoch: 295, [140/560, 83%], loss is 0.830497\n",
      "Training Epoch: 295, [210/560, 84%], loss is 1.232788\n",
      "Training Epoch: 295, [280/560, 96%], loss is 1.356076\n",
      "Training Epoch: 295, [350/560, 91%], loss is 1.537360\n",
      "Training Epoch: 295, [420/560, 93%], loss is 1.808366\n",
      "Training Epoch: 295, [490/560, 89%], loss is 2.191907\n",
      "Training Epoch: 300, [0/560, 93%], loss is 0.185356\n",
      "Training Epoch: 300, [70/560, 90%], loss is 0.379850\n",
      "Training Epoch: 300, [140/560, 93%], loss is 0.583175\n",
      "Training Epoch: 300, [210/560, 93%], loss is 0.812672\n",
      "Training Epoch: 300, [280/560, 97%], loss is 0.878889\n",
      "Training Epoch: 300, [350/560, 91%], loss is 1.126042\n",
      "Training Epoch: 300, [420/560, 90%], loss is 1.399896\n",
      "Training Epoch: 300, [490/560, 91%], loss is 1.647758\n",
      "Training Epoch: 305, [0/560, 91%], loss is 0.285771\n",
      "Training Epoch: 305, [70/560, 89%], loss is 0.528968\n",
      "Training Epoch: 305, [140/560, 93%], loss is 0.724342\n",
      "Training Epoch: 305, [210/560, 91%], loss is 1.024928\n",
      "Training Epoch: 305, [280/560, 93%], loss is 1.204716\n",
      "Training Epoch: 305, [350/560, 94%], loss is 1.356045\n",
      "Training Epoch: 305, [420/560, 94%], loss is 1.503682\n",
      "Training Epoch: 305, [490/560, 94%], loss is 1.707206\n",
      "Training Epoch: 310, [0/560, 89%], loss is 0.208687\n",
      "Training Epoch: 310, [70/560, 93%], loss is 0.419025\n",
      "Training Epoch: 310, [140/560, 93%], loss is 0.571579\n",
      "Training Epoch: 310, [210/560, 89%], loss is 0.870863\n",
      "Training Epoch: 310, [280/560, 93%], loss is 1.110406\n",
      "Training Epoch: 310, [350/560, 90%], loss is 1.339580\n",
      "Training Epoch: 310, [420/560, 91%], loss is 1.529121\n",
      "Training Epoch: 310, [490/560, 96%], loss is 1.675713\n",
      "Training Epoch: 315, [0/560, 99%], loss is 0.093646\n",
      "Best Epoch is 315\n",
      "Training Epoch: 315, [70/560, 93%], loss is 0.293759\n",
      "Training Epoch: 315, [140/560, 93%], loss is 0.472105\n",
      "Training Epoch: 315, [210/560, 93%], loss is 0.730157\n",
      "Training Epoch: 315, [280/560, 90%], loss is 1.060819\n",
      "Training Epoch: 315, [350/560, 90%], loss is 1.349708\n",
      "Training Epoch: 315, [420/560, 93%], loss is 1.500370\n",
      "Training Epoch: 315, [490/560, 93%], loss is 1.709396\n",
      "Training Epoch: 320, [0/560, 94%], loss is 0.157080\n",
      "Training Epoch: 320, [70/560, 99%], loss is 0.261947\n",
      "Training Epoch: 320, [140/560, 94%], loss is 0.431643\n",
      "Training Epoch: 320, [210/560, 90%], loss is 0.664883\n",
      "Training Epoch: 320, [280/560, 83%], loss is 1.042752\n",
      "Training Epoch: 320, [350/560, 93%], loss is 1.267871\n",
      "Training Epoch: 320, [420/560, 99%], loss is 1.354622\n",
      "Training Epoch: 320, [490/560, 86%], loss is 1.619076\n",
      "Training Epoch: 325, [0/560, 89%], loss is 0.320105\n",
      "Training Epoch: 325, [70/560, 93%], loss is 0.502408\n",
      "Training Epoch: 325, [140/560, 93%], loss is 0.623058\n",
      "Training Epoch: 325, [210/560, 89%], loss is 0.864778\n",
      "Training Epoch: 325, [280/560, 96%], loss is 1.019901\n",
      "Training Epoch: 325, [350/560, 94%], loss is 1.222621\n",
      "Training Epoch: 325, [420/560, 90%], loss is 1.517339\n",
      "Training Epoch: 325, [490/560, 91%], loss is 1.788062\n",
      "Training Epoch: 330, [0/560, 89%], loss is 0.311193\n",
      "Training Epoch: 330, [70/560, 94%], loss is 0.400491\n",
      "Training Epoch: 330, [140/560, 89%], loss is 0.672269\n",
      "Training Epoch: 330, [210/560, 97%], loss is 0.822602\n",
      "Training Epoch: 330, [280/560, 86%], loss is 1.129281\n",
      "Training Epoch: 330, [350/560, 91%], loss is 1.320253\n",
      "Training Epoch: 330, [420/560, 94%], loss is 1.526490\n",
      "Training Epoch: 330, [490/560, 91%], loss is 1.722771\n",
      "Training Epoch: 335, [0/560, 93%], loss is 0.194293\n",
      "Training Epoch: 335, [70/560, 90%], loss is 0.416087\n",
      "Training Epoch: 335, [140/560, 94%], loss is 0.588444\n",
      "Training Epoch: 335, [210/560, 91%], loss is 0.784304\n",
      "Training Epoch: 335, [280/560, 96%], loss is 0.886182\n",
      "Training Epoch: 335, [350/560, 93%], loss is 1.071823\n",
      "Training Epoch: 335, [420/560, 91%], loss is 1.256622\n",
      "Training Epoch: 335, [490/560, 93%], loss is 1.448103\n",
      "Training Epoch: 340, [0/560, 94%], loss is 0.149027\n",
      "Training Epoch: 340, [70/560, 87%], loss is 0.470726\n",
      "Training Epoch: 340, [140/560, 87%], loss is 0.839910\n",
      "Training Epoch: 340, [210/560, 90%], loss is 1.095937\n",
      "Training Epoch: 340, [280/560, 93%], loss is 1.300448\n",
      "Training Epoch: 340, [350/560, 93%], loss is 1.518655\n",
      "Training Epoch: 340, [420/560, 90%], loss is 1.720092\n",
      "Training Epoch: 340, [490/560, 89%], loss is 1.943377\n",
      "Training Epoch: 345, [0/560, 96%], loss is 0.118238\n",
      "Training Epoch: 345, [70/560, 93%], loss is 0.325822\n",
      "Training Epoch: 345, [140/560, 93%], loss is 0.483636\n",
      "Training Epoch: 345, [210/560, 96%], loss is 0.600292\n",
      "Training Epoch: 345, [280/560, 91%], loss is 0.822957\n",
      "Training Epoch: 345, [350/560, 90%], loss is 1.007557\n",
      "Training Epoch: 345, [420/560, 99%], loss is 1.128399\n",
      "Training Epoch: 345, [490/560, 96%], loss is 1.275198\n",
      "Training Epoch: 350, [0/560, 94%], loss is 0.107921\n",
      "Training Epoch: 350, [70/560, 93%], loss is 0.289712\n",
      "Training Epoch: 350, [140/560, 91%], loss is 0.541670\n",
      "Training Epoch: 350, [210/560, 93%], loss is 0.748583\n",
      "Training Epoch: 350, [280/560, 94%], loss is 0.871829\n",
      "Training Epoch: 350, [350/560, 86%], loss is 1.277512\n",
      "Training Epoch: 350, [420/560, 96%], loss is 1.414934\n",
      "Training Epoch: 350, [490/560, 90%], loss is 1.617019\n",
      "Training Epoch: 355, [0/560, 90%], loss is 0.316671\n",
      "Training Epoch: 355, [70/560, 87%], loss is 0.652430\n",
      "Training Epoch: 355, [140/560, 86%], loss is 1.035086\n",
      "Training Epoch: 355, [210/560, 83%], loss is 1.335240\n",
      "Training Epoch: 355, [280/560, 97%], loss is 1.488817\n",
      "Training Epoch: 355, [350/560, 94%], loss is 1.662418\n",
      "Training Epoch: 355, [420/560, 83%], loss is 2.153995\n",
      "Training Epoch: 355, [490/560, 86%], loss is 2.483638\n",
      "Training Epoch: 360, [0/560, 93%], loss is 0.146194\n",
      "Training Epoch: 360, [70/560, 96%], loss is 0.276820\n",
      "Training Epoch: 360, [140/560, 86%], loss is 0.723578\n",
      "Training Epoch: 360, [210/560, 93%], loss is 0.863012\n",
      "Training Epoch: 360, [280/560, 91%], loss is 1.080857\n",
      "Training Epoch: 360, [350/560, 91%], loss is 1.263109\n",
      "Training Epoch: 360, [420/560, 90%], loss is 1.569031\n",
      "Training Epoch: 360, [490/560, 91%], loss is 1.832632\n",
      "Training Epoch: 365, [0/560, 93%], loss is 0.132379\n",
      "Training Epoch: 365, [70/560, 94%], loss is 0.396673\n",
      "Training Epoch: 365, [140/560, 96%], loss is 0.562683\n",
      "Training Epoch: 365, [210/560, 93%], loss is 0.727419\n",
      "Training Epoch: 365, [280/560, 93%], loss is 0.887339\n",
      "Training Epoch: 365, [350/560, 90%], loss is 1.124442\n",
      "Training Epoch: 365, [420/560, 89%], loss is 1.373529\n",
      "Training Epoch: 365, [490/560, 94%], loss is 1.588169\n",
      "Training Epoch: 370, [0/560, 94%], loss is 0.154925\n",
      "Training Epoch: 370, [70/560, 94%], loss is 0.298449\n",
      "Training Epoch: 370, [140/560, 89%], loss is 0.532567\n",
      "Training Epoch: 370, [210/560, 93%], loss is 0.720850\n",
      "Training Epoch: 370, [280/560, 94%], loss is 0.864149\n",
      "Training Epoch: 370, [350/560, 96%], loss is 0.955448\n",
      "Training Epoch: 370, [420/560, 86%], loss is 1.207782\n",
      "Training Epoch: 370, [490/560, 94%], loss is 1.349324\n",
      "Training Epoch: 375, [0/560, 90%], loss is 0.235231\n",
      "Training Epoch: 375, [70/560, 96%], loss is 0.336343\n",
      "Training Epoch: 375, [140/560, 93%], loss is 0.506353\n",
      "Training Epoch: 375, [210/560, 93%], loss is 0.686028\n",
      "Training Epoch: 375, [280/560, 93%], loss is 0.856456\n",
      "Training Epoch: 375, [350/560, 87%], loss is 1.174179\n",
      "Training Epoch: 375, [420/560, 91%], loss is 1.471093\n",
      "Training Epoch: 375, [490/560, 91%], loss is 1.754658\n",
      "Training Epoch: 380, [0/560, 93%], loss is 0.158035\n",
      "Training Epoch: 380, [70/560, 84%], loss is 0.492723\n",
      "Training Epoch: 380, [140/560, 96%], loss is 0.697821\n",
      "Training Epoch: 380, [210/560, 93%], loss is 0.868238\n",
      "Training Epoch: 380, [280/560, 87%], loss is 1.199566\n",
      "Training Epoch: 380, [350/560, 90%], loss is 1.373492\n",
      "Training Epoch: 380, [420/560, 90%], loss is 1.579385\n",
      "Training Epoch: 380, [490/560, 93%], loss is 1.762411\n",
      "Training Epoch: 385, [0/560, 93%], loss is 0.198596\n",
      "Training Epoch: 385, [70/560, 97%], loss is 0.309358\n",
      "Training Epoch: 385, [140/560, 96%], loss is 0.403504\n",
      "Training Epoch: 385, [210/560, 93%], loss is 0.580962\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch: 385, [280/560, 94%], loss is 0.753299\n",
      "Training Epoch: 385, [350/560, 93%], loss is 0.926032\n",
      "Training Epoch: 385, [420/560, 99%], loss is 1.010365\n",
      "Training Epoch: 385, [490/560, 89%], loss is 1.248814\n",
      "Training Epoch: 390, [0/560, 93%], loss is 0.170459\n",
      "Training Epoch: 390, [70/560, 90%], loss is 0.342867\n",
      "Training Epoch: 390, [140/560, 94%], loss is 0.539894\n",
      "Training Epoch: 390, [210/560, 90%], loss is 0.747378\n",
      "Training Epoch: 390, [280/560, 93%], loss is 0.906161\n",
      "Training Epoch: 390, [350/560, 90%], loss is 1.146312\n",
      "Training Epoch: 390, [420/560, 86%], loss is 1.394982\n",
      "Training Epoch: 390, [490/560, 96%], loss is 1.558121\n",
      "Training Epoch: 395, [0/560, 87%], loss is 0.325963\n",
      "Training Epoch: 395, [70/560, 90%], loss is 0.528606\n",
      "Training Epoch: 395, [140/560, 87%], loss is 0.915777\n",
      "Training Epoch: 395, [210/560, 91%], loss is 1.144340\n",
      "Training Epoch: 395, [280/560, 86%], loss is 1.477746\n",
      "Training Epoch: 395, [350/560, 94%], loss is 1.603118\n",
      "Training Epoch: 395, [420/560, 99%], loss is 1.721637\n",
      "Training Epoch: 395, [490/560, 94%], loss is 1.927827\n",
      "Training Epoch: 400, [0/560, 94%], loss is 0.118120\n",
      "Training Epoch: 400, [70/560, 90%], loss is 0.314401\n",
      "Training Epoch: 400, [140/560, 94%], loss is 0.421444\n",
      "Training Epoch: 400, [210/560, 91%], loss is 0.644711\n",
      "Training Epoch: 400, [280/560, 97%], loss is 0.749087\n",
      "Training Epoch: 400, [350/560, 93%], loss is 0.956806\n",
      "Training Epoch: 400, [420/560, 91%], loss is 1.135697\n",
      "Training Epoch: 400, [490/560, 94%], loss is 1.287380\n",
      "Training Epoch: 405, [0/560, 96%], loss is 0.168513\n",
      "Training Epoch: 405, [70/560, 91%], loss is 0.414548\n",
      "Training Epoch: 405, [140/560, 86%], loss is 0.826715\n",
      "Training Epoch: 405, [210/560, 97%], loss is 0.934396\n",
      "Training Epoch: 405, [280/560, 90%], loss is 1.165691\n",
      "Training Epoch: 405, [350/560, 91%], loss is 1.403488\n",
      "Training Epoch: 405, [420/560, 94%], loss is 1.608194\n",
      "Training Epoch: 405, [490/560, 93%], loss is 1.765129\n",
      "Training Epoch: 410, [0/560, 79%], loss is 0.506094\n",
      "Training Epoch: 410, [70/560, 90%], loss is 0.742078\n",
      "Training Epoch: 410, [140/560, 86%], loss is 0.972524\n",
      "Training Epoch: 410, [210/560, 94%], loss is 1.090817\n",
      "Training Epoch: 410, [280/560, 90%], loss is 1.314287\n",
      "Training Epoch: 410, [350/560, 90%], loss is 1.543051\n",
      "Training Epoch: 410, [420/560, 90%], loss is 1.747188\n",
      "Training Epoch: 410, [490/560, 84%], loss is 2.198420\n",
      "Training Epoch: 415, [0/560, 93%], loss is 0.134066\n",
      "Training Epoch: 415, [70/560, 93%], loss is 0.301141\n",
      "Training Epoch: 415, [140/560, 89%], loss is 0.529436\n",
      "Training Epoch: 415, [210/560, 94%], loss is 0.701612\n",
      "Training Epoch: 415, [280/560, 93%], loss is 0.923533\n",
      "Training Epoch: 415, [350/560, 94%], loss is 1.056290\n",
      "Training Epoch: 415, [420/560, 90%], loss is 1.264240\n",
      "Training Epoch: 415, [490/560, 91%], loss is 1.607551\n",
      "Training Epoch: 420, [0/560, 90%], loss is 0.282983\n",
      "Training Epoch: 420, [70/560, 91%], loss is 0.476373\n",
      "Training Epoch: 420, [140/560, 96%], loss is 0.579615\n",
      "Training Epoch: 420, [210/560, 89%], loss is 0.938179\n",
      "Training Epoch: 420, [280/560, 90%], loss is 1.216734\n",
      "Training Epoch: 420, [350/560, 93%], loss is 1.357405\n",
      "Training Epoch: 420, [420/560, 89%], loss is 1.569824\n",
      "Training Epoch: 420, [490/560, 86%], loss is 1.894808\n",
      "Training Epoch: 425, [0/560, 94%], loss is 0.199005\n",
      "Training Epoch: 425, [70/560, 86%], loss is 0.560378\n",
      "Training Epoch: 425, [140/560, 93%], loss is 0.885618\n",
      "Training Epoch: 425, [210/560, 91%], loss is 1.141591\n",
      "Training Epoch: 425, [280/560, 89%], loss is 1.477376\n",
      "Training Epoch: 425, [350/560, 90%], loss is 1.730661\n",
      "Training Epoch: 425, [420/560, 90%], loss is 1.951868\n",
      "Training Epoch: 425, [490/560, 93%], loss is 2.102417\n",
      "Training Epoch: 430, [0/560, 96%], loss is 0.128939\n",
      "Training Epoch: 430, [70/560, 93%], loss is 0.329635\n",
      "Training Epoch: 430, [140/560, 91%], loss is 0.542228\n",
      "Training Epoch: 430, [210/560, 86%], loss is 0.924244\n",
      "Training Epoch: 430, [280/560, 96%], loss is 1.044696\n",
      "Training Epoch: 430, [350/560, 99%], loss is 1.125396\n",
      "Training Epoch: 430, [420/560, 94%], loss is 1.275794\n",
      "Training Epoch: 430, [490/560, 91%], loss is 1.492530\n",
      "Training Epoch: 435, [0/560, 94%], loss is 0.142289\n",
      "Training Epoch: 435, [70/560, 94%], loss is 0.339112\n",
      "Training Epoch: 435, [140/560, 94%], loss is 0.528820\n",
      "Training Epoch: 435, [210/560, 97%], loss is 0.642536\n",
      "Training Epoch: 435, [280/560, 89%], loss is 0.889103\n",
      "Training Epoch: 435, [350/560, 97%], loss is 0.999806\n",
      "Training Epoch: 435, [420/560, 94%], loss is 1.112945\n",
      "Training Epoch: 435, [490/560, 93%], loss is 1.273430\n",
      "Training Epoch: 440, [0/560, 96%], loss is 0.142346\n",
      "Training Epoch: 440, [70/560, 90%], loss is 0.442583\n",
      "Training Epoch: 440, [140/560, 93%], loss is 0.724118\n",
      "Training Epoch: 440, [210/560, 90%], loss is 0.994123\n",
      "Training Epoch: 440, [280/560, 93%], loss is 1.138825\n",
      "Training Epoch: 440, [350/560, 86%], loss is 1.481428\n",
      "Training Epoch: 440, [420/560, 91%], loss is 1.706999\n",
      "Training Epoch: 440, [490/560, 97%], loss is 1.807840\n",
      "Training Epoch: 445, [0/560, 91%], loss is 0.190083\n",
      "Training Epoch: 445, [70/560, 97%], loss is 0.318001\n",
      "Training Epoch: 445, [140/560, 87%], loss is 0.585162\n",
      "Training Epoch: 445, [210/560, 94%], loss is 0.734705\n",
      "Training Epoch: 445, [280/560, 93%], loss is 0.925498\n",
      "Training Epoch: 445, [350/560, 91%], loss is 1.076663\n",
      "Training Epoch: 445, [420/560, 90%], loss is 1.279405\n",
      "Training Epoch: 445, [490/560, 97%], loss is 1.395359\n",
      "Training Epoch: 450, [0/560, 93%], loss is 0.192135\n",
      "Training Epoch: 450, [70/560, 87%], loss is 0.432391\n",
      "Training Epoch: 450, [140/560, 93%], loss is 0.644220\n",
      "Training Epoch: 450, [210/560, 90%], loss is 0.876306\n",
      "Training Epoch: 450, [280/560, 96%], loss is 1.313724\n",
      "Training Epoch: 450, [350/560, 89%], loss is 1.581151\n",
      "Training Epoch: 450, [420/560, 90%], loss is 1.900235\n",
      "Training Epoch: 450, [490/560, 90%], loss is 2.229030\n",
      "Training Epoch: 455, [0/560, 93%], loss is 0.162598\n",
      "Training Epoch: 455, [70/560, 90%], loss is 0.376907\n",
      "Training Epoch: 455, [140/560, 91%], loss is 0.621871\n",
      "Training Epoch: 455, [210/560, 90%], loss is 0.897308\n",
      "Training Epoch: 455, [280/560, 96%], loss is 1.042179\n",
      "Training Epoch: 455, [350/560, 87%], loss is 1.329605\n",
      "Training Epoch: 455, [420/560, 93%], loss is 1.672529\n",
      "Training Epoch: 455, [490/560, 89%], loss is 1.881270\n",
      "Training Epoch: 460, [0/560, 96%], loss is 0.186545\n",
      "Training Epoch: 460, [70/560, 94%], loss is 0.356229\n",
      "Training Epoch: 460, [140/560, 93%], loss is 0.528343\n",
      "Training Epoch: 460, [210/560, 91%], loss is 0.746559\n",
      "Training Epoch: 460, [280/560, 86%], loss is 1.073820\n",
      "Training Epoch: 460, [350/560, 91%], loss is 1.280191\n",
      "Training Epoch: 460, [420/560, 94%], loss is 1.441262\n",
      "Training Epoch: 460, [490/560, 90%], loss is 1.754870\n",
      "Training Epoch: 465, [0/560, 94%], loss is 0.150468\n",
      "Training Epoch: 465, [70/560, 93%], loss is 0.391941\n",
      "Training Epoch: 465, [140/560, 100%], loss is 0.471665\n",
      "Training Epoch: 465, [210/560, 93%], loss is 0.662673\n",
      "Training Epoch: 465, [280/560, 91%], loss is 0.892997\n",
      "Training Epoch: 465, [350/560, 91%], loss is 1.024322\n",
      "Training Epoch: 465, [420/560, 93%], loss is 1.180337\n",
      "Training Epoch: 465, [490/560, 87%], loss is 1.495705\n",
      "Training Epoch: 470, [0/560, 93%], loss is 0.144188\n",
      "Training Epoch: 470, [70/560, 90%], loss is 0.367033\n",
      "Training Epoch: 470, [140/560, 94%], loss is 0.499908\n",
      "Training Epoch: 470, [210/560, 91%], loss is 0.680826\n",
      "Training Epoch: 470, [280/560, 91%], loss is 0.956040\n",
      "Training Epoch: 470, [350/560, 96%], loss is 1.085276\n",
      "Training Epoch: 470, [420/560, 94%], loss is 1.211681\n",
      "Training Epoch: 470, [490/560, 90%], loss is 1.437347\n",
      "Training Epoch: 475, [0/560, 93%], loss is 0.146506\n",
      "Training Epoch: 475, [70/560, 91%], loss is 0.340688\n",
      "Training Epoch: 475, [140/560, 99%], loss is 0.437992\n",
      "Training Epoch: 475, [210/560, 94%], loss is 0.583835\n",
      "Training Epoch: 475, [280/560, 99%], loss is 0.674713\n",
      "Training Epoch: 475, [350/560, 100%], loss is 0.736551\n",
      "Training Epoch: 475, [420/560, 93%], loss is 0.938438\n",
      "Training Epoch: 475, [490/560, 91%], loss is 1.128891\n",
      "Training Epoch: 480, [0/560, 91%], loss is 0.174671\n",
      "Training Epoch: 480, [70/560, 93%], loss is 0.360886\n",
      "Training Epoch: 480, [140/560, 99%], loss is 0.408512\n",
      "Training Epoch: 480, [210/560, 94%], loss is 0.650004\n",
      "Training Epoch: 480, [280/560, 96%], loss is 0.756746\n",
      "Training Epoch: 480, [350/560, 91%], loss is 0.928615\n",
      "Training Epoch: 480, [420/560, 100%], loss is 0.993419\n",
      "Training Epoch: 480, [490/560, 96%], loss is 1.182083\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch: 485, [0/560, 89%], loss is 0.197677\n",
      "Training Epoch: 485, [70/560, 91%], loss is 0.425612\n",
      "Training Epoch: 485, [140/560, 96%], loss is 0.567287\n",
      "Training Epoch: 485, [210/560, 91%], loss is 0.823133\n",
      "Training Epoch: 485, [280/560, 96%], loss is 0.914539\n",
      "Training Epoch: 485, [350/560, 89%], loss is 1.230431\n",
      "Training Epoch: 485, [420/560, 96%], loss is 1.389185\n",
      "Training Epoch: 485, [490/560, 91%], loss is 1.613165\n",
      "Training Epoch: 490, [0/560, 87%], loss is 0.308515\n",
      "Training Epoch: 490, [70/560, 87%], loss is 0.514246\n",
      "Training Epoch: 490, [140/560, 91%], loss is 0.725469\n",
      "Training Epoch: 490, [210/560, 93%], loss is 0.939022\n",
      "Training Epoch: 490, [280/560, 93%], loss is 1.126212\n",
      "Training Epoch: 490, [350/560, 87%], loss is 1.641490\n",
      "Training Epoch: 490, [420/560, 87%], loss is 1.953849\n",
      "Training Epoch: 490, [490/560, 90%], loss is 2.328290\n",
      "Training Epoch: 495, [0/560, 91%], loss is 0.199546\n",
      "Training Epoch: 495, [70/560, 93%], loss is 0.399698\n",
      "Training Epoch: 495, [140/560, 87%], loss is 0.725117\n",
      "Training Epoch: 495, [210/560, 89%], loss is 1.019694\n",
      "Training Epoch: 495, [280/560, 90%], loss is 1.237485\n",
      "Training Epoch: 495, [350/560, 91%], loss is 1.454561\n",
      "Training Epoch: 495, [420/560, 91%], loss is 1.700794\n",
      "Training Epoch: 495, [490/560, 94%], loss is 1.860235\n",
      "Training Epoch: 500, [0/560, 94%], loss is 0.128377\n",
      "Training Epoch: 500, [70/560, 99%], loss is 0.242596\n",
      "Training Epoch: 500, [140/560, 97%], loss is 0.334639\n",
      "Training Epoch: 500, [210/560, 96%], loss is 0.427742\n",
      "Training Epoch: 500, [280/560, 90%], loss is 0.606402\n",
      "Training Epoch: 500, [350/560, 97%], loss is 0.711662\n",
      "Training Epoch: 500, [420/560, 94%], loss is 0.843001\n",
      "Training Epoch: 500, [490/560, 97%], loss is 0.964845\n",
      "Training Epoch: 505, [0/560, 90%], loss is 0.272481\n",
      "Training Epoch: 505, [70/560, 91%], loss is 0.505196\n",
      "Training Epoch: 505, [140/560, 99%], loss is 0.583349\n",
      "Training Epoch: 505, [210/560, 93%], loss is 0.835541\n",
      "Training Epoch: 505, [280/560, 94%], loss is 0.968992\n",
      "Training Epoch: 505, [350/560, 99%], loss is 1.062786\n",
      "Training Epoch: 505, [420/560, 96%], loss is 1.198904\n",
      "Training Epoch: 505, [490/560, 96%], loss is 1.288883\n",
      "Training Epoch: 510, [0/560, 96%], loss is 0.097825\n",
      "Training Epoch: 510, [70/560, 93%], loss is 0.295949\n",
      "Training Epoch: 510, [140/560, 100%], loss is 0.398490\n",
      "Training Epoch: 510, [210/560, 94%], loss is 0.533843\n",
      "Training Epoch: 510, [280/560, 93%], loss is 0.693138\n",
      "Training Epoch: 510, [350/560, 97%], loss is 0.787293\n",
      "Training Epoch: 510, [420/560, 94%], loss is 0.980770\n",
      "Training Epoch: 510, [490/560, 93%], loss is 1.168698\n",
      "Training Epoch: 515, [0/560, 94%], loss is 0.178862\n",
      "Training Epoch: 515, [70/560, 93%], loss is 0.356371\n",
      "Training Epoch: 515, [140/560, 93%], loss is 0.532458\n",
      "Training Epoch: 515, [210/560, 94%], loss is 0.675141\n",
      "Training Epoch: 515, [280/560, 96%], loss is 0.812847\n",
      "Training Epoch: 515, [350/560, 94%], loss is 0.950881\n",
      "Training Epoch: 515, [420/560, 96%], loss is 1.020003\n",
      "Training Epoch: 515, [490/560, 96%], loss is 1.141314\n",
      "Training Epoch: 520, [0/560, 94%], loss is 0.184335\n",
      "Training Epoch: 520, [70/560, 93%], loss is 0.413937\n",
      "Training Epoch: 520, [140/560, 86%], loss is 1.048693\n",
      "Training Epoch: 520, [210/560, 93%], loss is 1.208951\n",
      "Training Epoch: 520, [280/560, 91%], loss is 1.535136\n",
      "Training Epoch: 520, [350/560, 90%], loss is 1.767745\n",
      "Training Epoch: 520, [420/560, 93%], loss is 1.920667\n",
      "Training Epoch: 520, [490/560, 90%], loss is 2.277936\n",
      "Training Epoch: 525, [0/560, 81%], loss is 0.457194\n",
      "Training Epoch: 525, [70/560, 86%], loss is 0.679006\n",
      "Training Epoch: 525, [140/560, 90%], loss is 0.933385\n",
      "Training Epoch: 525, [210/560, 90%], loss is 1.168611\n",
      "Training Epoch: 525, [280/560, 96%], loss is 1.302242\n",
      "Training Epoch: 525, [350/560, 90%], loss is 1.537534\n",
      "Training Epoch: 525, [420/560, 89%], loss is 1.836370\n",
      "Training Epoch: 525, [490/560, 90%], loss is 2.030634\n",
      "Training Epoch: 530, [0/560, 93%], loss is 0.141880\n",
      "Training Epoch: 530, [70/560, 91%], loss is 0.322626\n",
      "Training Epoch: 530, [140/560, 97%], loss is 0.398566\n",
      "Training Epoch: 530, [210/560, 96%], loss is 0.525080\n",
      "Training Epoch: 530, [280/560, 94%], loss is 0.629360\n",
      "Training Epoch: 530, [350/560, 91%], loss is 0.822085\n",
      "Training Epoch: 530, [420/560, 96%], loss is 0.963570\n",
      "Training Epoch: 530, [490/560, 94%], loss is 1.269917\n",
      "Training Epoch: 535, [0/560, 96%], loss is 0.089214\n",
      "Best Epoch is 535\n",
      "Training Epoch: 535, [70/560, 96%], loss is 0.216213\n",
      "Training Epoch: 535, [140/560, 91%], loss is 0.424237\n",
      "Training Epoch: 535, [210/560, 90%], loss is 0.638300\n",
      "Training Epoch: 535, [280/560, 91%], loss is 0.877870\n",
      "Training Epoch: 535, [350/560, 93%], loss is 1.038539\n",
      "Training Epoch: 535, [420/560, 94%], loss is 1.191193\n",
      "Training Epoch: 535, [490/560, 83%], loss is 1.470910\n",
      "Training Epoch: 540, [0/560, 94%], loss is 0.136804\n",
      "Training Epoch: 540, [70/560, 96%], loss is 0.240570\n",
      "Training Epoch: 540, [140/560, 97%], loss is 0.380039\n",
      "Training Epoch: 540, [210/560, 94%], loss is 0.525670\n",
      "Training Epoch: 540, [280/560, 87%], loss is 0.898245\n",
      "Training Epoch: 540, [350/560, 96%], loss is 1.025476\n",
      "Training Epoch: 540, [420/560, 94%], loss is 1.171106\n",
      "Training Epoch: 540, [490/560, 93%], loss is 1.290938\n",
      "Training Epoch: 545, [0/560, 93%], loss is 0.178967\n",
      "Training Epoch: 545, [70/560, 94%], loss is 0.338827\n",
      "Training Epoch: 545, [140/560, 99%], loss is 0.443658\n",
      "Training Epoch: 545, [210/560, 87%], loss is 0.709402\n",
      "Training Epoch: 545, [280/560, 96%], loss is 0.842555\n",
      "Training Epoch: 545, [350/560, 94%], loss is 0.977055\n",
      "Training Epoch: 545, [420/560, 91%], loss is 1.228564\n",
      "Training Epoch: 545, [490/560, 91%], loss is 1.497222\n",
      "Training Epoch: 550, [0/560, 96%], loss is 0.114817\n",
      "Training Epoch: 550, [70/560, 97%], loss is 0.237140\n",
      "Training Epoch: 550, [140/560, 89%], loss is 0.493551\n",
      "Training Epoch: 550, [210/560, 97%], loss is 0.598458\n",
      "Training Epoch: 550, [280/560, 93%], loss is 0.726380\n",
      "Training Epoch: 550, [350/560, 93%], loss is 1.025835\n",
      "Training Epoch: 550, [420/560, 91%], loss is 1.411883\n",
      "Training Epoch: 550, [490/560, 97%], loss is 1.534531\n",
      "Training Epoch: 555, [0/560, 89%], loss is 0.411340\n",
      "Training Epoch: 555, [70/560, 90%], loss is 0.638079\n",
      "Training Epoch: 555, [140/560, 93%], loss is 0.852260\n",
      "Training Epoch: 555, [210/560, 84%], loss is 1.176841\n",
      "Training Epoch: 555, [280/560, 90%], loss is 1.519033\n",
      "Training Epoch: 555, [350/560, 93%], loss is 1.777476\n",
      "Training Epoch: 555, [420/560, 89%], loss is 2.071123\n",
      "Training Epoch: 555, [490/560, 99%], loss is 2.158846\n",
      "Training Epoch: 560, [0/560, 93%], loss is 0.147039\n",
      "Training Epoch: 560, [70/560, 96%], loss is 0.324609\n",
      "Training Epoch: 560, [140/560, 90%], loss is 0.642792\n",
      "Training Epoch: 560, [210/560, 89%], loss is 0.907303\n",
      "Training Epoch: 560, [280/560, 90%], loss is 1.115549\n",
      "Training Epoch: 560, [350/560, 93%], loss is 1.296101\n",
      "Training Epoch: 560, [420/560, 91%], loss is 1.485734\n",
      "Training Epoch: 560, [490/560, 97%], loss is 1.597606\n",
      "Training Epoch: 565, [0/560, 100%], loss is 0.042484\n",
      "Best Epoch is 565\n",
      "Training Epoch: 565, [70/560, 93%], loss is 0.189668\n",
      "Training Epoch: 565, [140/560, 97%], loss is 0.264595\n",
      "Training Epoch: 565, [210/560, 99%], loss is 0.373071\n",
      "Training Epoch: 565, [280/560, 94%], loss is 0.529047\n",
      "Training Epoch: 565, [350/560, 89%], loss is 0.707874\n",
      "Training Epoch: 565, [420/560, 93%], loss is 0.848445\n",
      "Training Epoch: 565, [490/560, 94%], loss is 1.010888\n",
      "Training Epoch: 570, [0/560, 96%], loss is 0.138120\n",
      "Training Epoch: 570, [70/560, 93%], loss is 0.352843\n",
      "Training Epoch: 570, [140/560, 91%], loss is 0.537824\n",
      "Training Epoch: 570, [210/560, 89%], loss is 0.790485\n",
      "Training Epoch: 570, [280/560, 93%], loss is 0.992692\n",
      "Training Epoch: 570, [350/560, 96%], loss is 1.123306\n",
      "Training Epoch: 570, [420/560, 94%], loss is 1.244022\n",
      "Training Epoch: 570, [490/560, 87%], loss is 1.526759\n",
      "Training Epoch: 575, [0/560, 84%], loss is 0.286413\n",
      "Training Epoch: 575, [70/560, 93%], loss is 0.434653\n",
      "Training Epoch: 575, [140/560, 94%], loss is 0.561981\n",
      "Training Epoch: 575, [210/560, 93%], loss is 0.764905\n",
      "Training Epoch: 575, [280/560, 86%], loss is 1.008086\n",
      "Training Epoch: 575, [350/560, 91%], loss is 1.180270\n",
      "Training Epoch: 575, [420/560, 96%], loss is 1.309007\n",
      "Training Epoch: 575, [490/560, 91%], loss is 1.506320\n",
      "Training Epoch: 580, [0/560, 89%], loss is 0.304631\n",
      "Training Epoch: 580, [70/560, 90%], loss is 0.529098\n",
      "Training Epoch: 580, [140/560, 89%], loss is 0.738126\n",
      "Training Epoch: 580, [210/560, 93%], loss is 0.946296\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch: 580, [280/560, 93%], loss is 1.129709\n",
      "Training Epoch: 580, [350/560, 90%], loss is 1.397720\n",
      "Training Epoch: 580, [420/560, 90%], loss is 1.607150\n",
      "Training Epoch: 580, [490/560, 84%], loss is 1.862890\n",
      "Training Epoch: 585, [0/560, 91%], loss is 0.168264\n",
      "Training Epoch: 585, [70/560, 93%], loss is 0.286253\n",
      "Training Epoch: 585, [140/560, 90%], loss is 0.522859\n",
      "Training Epoch: 585, [210/560, 90%], loss is 0.689842\n",
      "Training Epoch: 585, [280/560, 94%], loss is 0.945497\n",
      "Training Epoch: 585, [350/560, 90%], loss is 1.139355\n",
      "Training Epoch: 585, [420/560, 93%], loss is 1.292773\n",
      "Training Epoch: 585, [490/560, 91%], loss is 1.498464\n",
      "Training Epoch: 590, [0/560, 97%], loss is 0.105133\n",
      "Training Epoch: 590, [70/560, 89%], loss is 0.404273\n",
      "Training Epoch: 590, [140/560, 94%], loss is 0.594297\n",
      "Training Epoch: 590, [210/560, 99%], loss is 0.701813\n",
      "Training Epoch: 590, [280/560, 99%], loss is 0.793814\n",
      "Training Epoch: 590, [350/560, 90%], loss is 1.010219\n",
      "Training Epoch: 590, [420/560, 93%], loss is 1.174804\n",
      "Training Epoch: 590, [490/560, 96%], loss is 1.279569\n",
      "Training Epoch: 595, [0/560, 89%], loss is 0.267817\n",
      "Training Epoch: 595, [70/560, 89%], loss is 0.496545\n",
      "Training Epoch: 595, [140/560, 90%], loss is 0.710279\n",
      "Training Epoch: 595, [210/560, 93%], loss is 0.874237\n",
      "Training Epoch: 595, [280/560, 94%], loss is 1.113568\n",
      "Training Epoch: 595, [350/560, 96%], loss is 1.310255\n",
      "Training Epoch: 595, [420/560, 90%], loss is 1.541947\n",
      "Training Epoch: 595, [490/560, 90%], loss is 1.757553\n",
      "Training Epoch: 600, [0/560, 83%], loss is 0.228144\n",
      "Training Epoch: 600, [70/560, 96%], loss is 0.439763\n",
      "Training Epoch: 600, [140/560, 91%], loss is 0.603500\n",
      "Training Epoch: 600, [210/560, 90%], loss is 0.964274\n",
      "Training Epoch: 600, [280/560, 94%], loss is 1.120537\n",
      "Training Epoch: 600, [350/560, 90%], loss is 1.329112\n",
      "Training Epoch: 600, [420/560, 94%], loss is 1.465685\n",
      "Training Epoch: 600, [490/560, 91%], loss is 1.641915\n",
      "Training Epoch: 605, [0/560, 93%], loss is 0.146502\n",
      "Training Epoch: 605, [70/560, 89%], loss is 0.362980\n",
      "Training Epoch: 605, [140/560, 90%], loss is 0.530609\n",
      "Training Epoch: 605, [210/560, 89%], loss is 0.773651\n",
      "Training Epoch: 605, [280/560, 96%], loss is 0.932717\n",
      "Training Epoch: 605, [350/560, 91%], loss is 1.160252\n",
      "Training Epoch: 605, [420/560, 96%], loss is 1.274336\n",
      "Training Epoch: 605, [490/560, 90%], loss is 1.565069\n",
      "Training Epoch: 610, [0/560, 97%], loss is 0.065052\n",
      "Training Epoch: 610, [70/560, 97%], loss is 0.194792\n",
      "Training Epoch: 610, [140/560, 96%], loss is 0.330132\n",
      "Training Epoch: 610, [210/560, 97%], loss is 0.430926\n",
      "Training Epoch: 610, [280/560, 91%], loss is 0.650181\n",
      "Training Epoch: 610, [350/560, 86%], loss is 0.918406\n",
      "Training Epoch: 610, [420/560, 90%], loss is 1.148121\n",
      "Training Epoch: 610, [490/560, 96%], loss is 1.282378\n",
      "Training Epoch: 615, [0/560, 94%], loss is 0.149236\n",
      "Training Epoch: 615, [70/560, 94%], loss is 0.342978\n",
      "Training Epoch: 615, [140/560, 94%], loss is 0.468350\n",
      "Training Epoch: 615, [210/560, 99%], loss is 0.543789\n",
      "Training Epoch: 615, [280/560, 89%], loss is 0.857749\n",
      "Training Epoch: 615, [350/560, 94%], loss is 0.999588\n",
      "Training Epoch: 615, [420/560, 89%], loss is 1.313503\n",
      "Training Epoch: 615, [490/560, 96%], loss is 1.441222\n",
      "Training Epoch: 620, [0/560, 87%], loss is 0.364378\n",
      "Training Epoch: 620, [70/560, 90%], loss is 0.597322\n",
      "Training Epoch: 620, [140/560, 91%], loss is 0.799104\n",
      "Training Epoch: 620, [210/560, 93%], loss is 0.975293\n",
      "Training Epoch: 620, [280/560, 93%], loss is 1.143076\n",
      "Training Epoch: 620, [350/560, 96%], loss is 1.235705\n",
      "Training Epoch: 620, [420/560, 90%], loss is 1.490814\n",
      "Training Epoch: 620, [490/560, 90%], loss is 1.735964\n",
      "Training Epoch: 625, [0/560, 93%], loss is 0.144500\n",
      "Training Epoch: 625, [70/560, 93%], loss is 0.288998\n",
      "Training Epoch: 625, [140/560, 93%], loss is 0.487836\n",
      "Training Epoch: 625, [210/560, 90%], loss is 0.631679\n",
      "Training Epoch: 625, [280/560, 96%], loss is 0.743276\n",
      "Training Epoch: 625, [350/560, 99%], loss is 0.830102\n",
      "Training Epoch: 625, [420/560, 91%], loss is 0.954979\n",
      "Training Epoch: 625, [490/560, 94%], loss is 1.074994\n",
      "Training Epoch: 630, [0/560, 100%], loss is 0.055480\n",
      "Training Epoch: 630, [70/560, 91%], loss is 0.223321\n",
      "Training Epoch: 630, [140/560, 93%], loss is 0.351927\n",
      "Training Epoch: 630, [210/560, 97%], loss is 0.437815\n",
      "Training Epoch: 630, [280/560, 94%], loss is 0.631336\n",
      "Training Epoch: 630, [350/560, 87%], loss is 0.898556\n",
      "Training Epoch: 630, [420/560, 99%], loss is 0.962308\n",
      "Training Epoch: 630, [490/560, 89%], loss is 1.196397\n",
      "Training Epoch: 635, [0/560, 90%], loss is 0.171378\n",
      "Training Epoch: 635, [70/560, 100%], loss is 0.283560\n",
      "Training Epoch: 635, [140/560, 89%], loss is 0.474069\n",
      "Training Epoch: 635, [210/560, 96%], loss is 0.575616\n",
      "Training Epoch: 635, [280/560, 90%], loss is 0.814541\n",
      "Training Epoch: 635, [350/560, 94%], loss is 0.966287\n",
      "Training Epoch: 635, [420/560, 94%], loss is 1.088430\n",
      "Training Epoch: 635, [490/560, 94%], loss is 1.267300\n",
      "Training Epoch: 640, [0/560, 83%], loss is 0.327557\n",
      "Training Epoch: 640, [70/560, 86%], loss is 0.636499\n",
      "Training Epoch: 640, [140/560, 93%], loss is 0.790293\n",
      "Training Epoch: 640, [210/560, 94%], loss is 0.995019\n",
      "Training Epoch: 640, [280/560, 93%], loss is 1.201441\n",
      "Training Epoch: 640, [350/560, 94%], loss is 1.350151\n",
      "Training Epoch: 640, [420/560, 93%], loss is 1.550973\n",
      "Training Epoch: 640, [490/560, 91%], loss is 1.797453\n",
      "Training Epoch: 645, [0/560, 91%], loss is 0.178799\n",
      "Training Epoch: 645, [70/560, 94%], loss is 0.298090\n",
      "Training Epoch: 645, [140/560, 90%], loss is 0.488704\n",
      "Training Epoch: 645, [210/560, 93%], loss is 0.687533\n",
      "Training Epoch: 645, [280/560, 94%], loss is 0.887371\n",
      "Training Epoch: 645, [350/560, 96%], loss is 0.988813\n",
      "Training Epoch: 645, [420/560, 96%], loss is 1.142853\n",
      "Training Epoch: 645, [490/560, 99%], loss is 1.229171\n",
      "Training Epoch: 650, [0/560, 93%], loss is 0.163581\n",
      "Training Epoch: 650, [70/560, 86%], loss is 0.543725\n",
      "Training Epoch: 650, [140/560, 87%], loss is 0.831197\n",
      "Training Epoch: 650, [210/560, 89%], loss is 1.069153\n",
      "Training Epoch: 650, [280/560, 81%], loss is 1.466597\n",
      "Training Epoch: 650, [350/560, 93%], loss is 1.633616\n",
      "Training Epoch: 650, [420/560, 93%], loss is 1.891424\n",
      "Training Epoch: 650, [490/560, 87%], loss is 2.195617\n",
      "Training Epoch: 655, [0/560, 96%], loss is 0.230413\n",
      "Training Epoch: 655, [70/560, 89%], loss is 0.603963\n",
      "Training Epoch: 655, [140/560, 90%], loss is 0.879987\n",
      "Training Epoch: 655, [210/560, 96%], loss is 1.019885\n",
      "Training Epoch: 655, [280/560, 93%], loss is 1.151889\n",
      "Training Epoch: 655, [350/560, 94%], loss is 1.298361\n",
      "Training Epoch: 655, [420/560, 91%], loss is 1.490320\n",
      "Training Epoch: 655, [490/560, 84%], loss is 2.268767\n",
      "Training Epoch: 660, [0/560, 91%], loss is 0.182907\n",
      "Training Epoch: 660, [70/560, 97%], loss is 0.310487\n",
      "Training Epoch: 660, [140/560, 93%], loss is 0.496076\n",
      "Training Epoch: 660, [210/560, 96%], loss is 0.599124\n",
      "Training Epoch: 660, [280/560, 87%], loss is 0.849989\n",
      "Training Epoch: 660, [350/560, 91%], loss is 1.030671\n",
      "Training Epoch: 660, [420/560, 96%], loss is 1.179439\n",
      "Training Epoch: 660, [490/560, 94%], loss is 1.384345\n",
      "Training Epoch: 665, [0/560, 94%], loss is 0.183583\n",
      "Training Epoch: 665, [70/560, 96%], loss is 0.372363\n",
      "Training Epoch: 665, [140/560, 90%], loss is 0.689858\n",
      "Training Epoch: 665, [210/560, 84%], loss is 1.053518\n",
      "Training Epoch: 665, [280/560, 94%], loss is 1.225714\n",
      "Training Epoch: 665, [350/560, 94%], loss is 1.344180\n",
      "Training Epoch: 665, [420/560, 96%], loss is 1.466326\n",
      "Training Epoch: 665, [490/560, 94%], loss is 1.637257\n",
      "Training Epoch: 670, [0/560, 96%], loss is 0.111511\n",
      "Training Epoch: 670, [70/560, 93%], loss is 0.268083\n",
      "Training Epoch: 670, [140/560, 94%], loss is 0.474392\n",
      "Training Epoch: 670, [210/560, 99%], loss is 0.554659\n",
      "Training Epoch: 670, [280/560, 93%], loss is 0.720625\n",
      "Training Epoch: 670, [350/560, 90%], loss is 0.925402\n",
      "Training Epoch: 670, [420/560, 91%], loss is 1.136575\n",
      "Training Epoch: 670, [490/560, 86%], loss is 1.411747\n",
      "Training Epoch: 675, [0/560, 91%], loss is 0.225612\n",
      "Training Epoch: 675, [70/560, 90%], loss is 0.415333\n",
      "Training Epoch: 675, [140/560, 90%], loss is 0.629232\n",
      "Training Epoch: 675, [210/560, 97%], loss is 0.809950\n",
      "Training Epoch: 675, [280/560, 89%], loss is 1.173037\n",
      "Training Epoch: 675, [350/560, 93%], loss is 1.535204\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch: 675, [420/560, 96%], loss is 1.703807\n",
      "Training Epoch: 675, [490/560, 99%], loss is 1.784582\n",
      "Training Epoch: 680, [0/560, 91%], loss is 0.173194\n",
      "Training Epoch: 680, [70/560, 99%], loss is 0.303033\n",
      "Training Epoch: 680, [140/560, 86%], loss is 0.847660\n",
      "Training Epoch: 680, [210/560, 97%], loss is 0.953287\n",
      "Training Epoch: 680, [280/560, 94%], loss is 1.113856\n",
      "Training Epoch: 680, [350/560, 91%], loss is 1.275981\n",
      "Training Epoch: 680, [420/560, 91%], loss is 1.480294\n",
      "Training Epoch: 680, [490/560, 97%], loss is 1.561155\n",
      "Training Epoch: 685, [0/560, 94%], loss is 0.123836\n",
      "Training Epoch: 685, [70/560, 96%], loss is 0.227818\n",
      "Training Epoch: 685, [140/560, 91%], loss is 0.453365\n",
      "Training Epoch: 685, [210/560, 93%], loss is 0.621996\n",
      "Training Epoch: 685, [280/560, 93%], loss is 0.789878\n",
      "Training Epoch: 685, [350/560, 90%], loss is 1.026976\n",
      "Training Epoch: 685, [420/560, 97%], loss is 1.151777\n",
      "Training Epoch: 685, [490/560, 90%], loss is 1.347301\n",
      "Training Epoch: 690, [0/560, 99%], loss is 0.045339\n",
      "Training Epoch: 690, [70/560, 97%], loss is 0.122313\n",
      "Training Epoch: 690, [140/560, 89%], loss is 0.388517\n",
      "Training Epoch: 690, [210/560, 99%], loss is 0.498273\n",
      "Training Epoch: 690, [280/560, 94%], loss is 0.682917\n",
      "Training Epoch: 690, [350/560, 97%], loss is 0.781474\n",
      "Training Epoch: 690, [420/560, 93%], loss is 1.003701\n",
      "Training Epoch: 690, [490/560, 96%], loss is 1.152233\n",
      "Training Epoch: 695, [0/560, 97%], loss is 0.093195\n",
      "Training Epoch: 695, [70/560, 96%], loss is 0.226130\n",
      "Training Epoch: 695, [140/560, 96%], loss is 0.333590\n",
      "Training Epoch: 695, [210/560, 96%], loss is 0.496932\n",
      "Training Epoch: 695, [280/560, 93%], loss is 0.692607\n",
      "Training Epoch: 695, [350/560, 91%], loss is 0.869642\n",
      "Training Epoch: 695, [420/560, 94%], loss is 1.043958\n",
      "Training Epoch: 695, [490/560, 91%], loss is 1.210105\n",
      "Training Epoch: 700, [0/560, 97%], loss is 0.083463\n",
      "Training Epoch: 700, [70/560, 94%], loss is 0.257825\n",
      "Training Epoch: 700, [140/560, 93%], loss is 0.529135\n",
      "Training Epoch: 700, [210/560, 94%], loss is 0.716266\n",
      "Training Epoch: 700, [280/560, 96%], loss is 0.836114\n",
      "Training Epoch: 700, [350/560, 96%], loss is 0.997691\n",
      "Training Epoch: 700, [420/560, 94%], loss is 1.145071\n",
      "Training Epoch: 700, [490/560, 97%], loss is 1.224954\n",
      "Training Epoch: 705, [0/560, 93%], loss is 0.173826\n",
      "Training Epoch: 705, [70/560, 99%], loss is 0.252183\n",
      "Training Epoch: 705, [140/560, 94%], loss is 0.373190\n",
      "Training Epoch: 705, [210/560, 90%], loss is 0.568755\n",
      "Training Epoch: 705, [280/560, 96%], loss is 0.680238\n",
      "Training Epoch: 705, [350/560, 87%], loss is 0.969810\n",
      "Training Epoch: 705, [420/560, 94%], loss is 1.090090\n",
      "Training Epoch: 705, [490/560, 96%], loss is 1.201295\n",
      "Training Epoch: 710, [0/560, 89%], loss is 0.346824\n",
      "Training Epoch: 710, [70/560, 94%], loss is 0.488221\n",
      "Training Epoch: 710, [140/560, 89%], loss is 0.755920\n",
      "Training Epoch: 710, [210/560, 89%], loss is 1.164111\n",
      "Training Epoch: 710, [280/560, 93%], loss is 1.321186\n",
      "Training Epoch: 710, [350/560, 89%], loss is 1.617465\n",
      "Training Epoch: 710, [420/560, 96%], loss is 1.765434\n",
      "Training Epoch: 710, [490/560, 93%], loss is 1.965681\n",
      "Training Epoch: 715, [0/560, 90%], loss is 0.258666\n",
      "Training Epoch: 715, [70/560, 93%], loss is 0.473825\n",
      "Training Epoch: 715, [140/560, 96%], loss is 0.599320\n",
      "Training Epoch: 715, [210/560, 91%], loss is 0.765954\n",
      "Training Epoch: 715, [280/560, 97%], loss is 0.882287\n",
      "Training Epoch: 715, [350/560, 93%], loss is 1.069587\n",
      "Training Epoch: 715, [420/560, 94%], loss is 1.208942\n",
      "Training Epoch: 715, [490/560, 90%], loss is 1.445830\n",
      "Training Epoch: 720, [0/560, 96%], loss is 0.105890\n",
      "Training Epoch: 720, [70/560, 96%], loss is 0.190173\n",
      "Training Epoch: 720, [140/560, 96%], loss is 0.328206\n",
      "Training Epoch: 720, [210/560, 97%], loss is 0.454178\n",
      "Training Epoch: 720, [280/560, 96%], loss is 0.573188\n",
      "Training Epoch: 720, [350/560, 96%], loss is 0.690033\n",
      "Training Epoch: 720, [420/560, 93%], loss is 0.886922\n",
      "Training Epoch: 720, [490/560, 91%], loss is 1.123565\n",
      "Training Epoch: 725, [0/560, 99%], loss is 0.069754\n",
      "Training Epoch: 725, [70/560, 99%], loss is 0.125965\n",
      "Training Epoch: 725, [140/560, 100%], loss is 0.179802\n",
      "Training Epoch: 725, [210/560, 94%], loss is 0.354090\n",
      "Training Epoch: 725, [280/560, 94%], loss is 0.568207\n",
      "Training Epoch: 725, [350/560, 94%], loss is 0.716846\n",
      "Training Epoch: 725, [420/560, 99%], loss is 0.767730\n",
      "Training Epoch: 725, [490/560, 96%], loss is 0.937779\n",
      "Training Epoch: 730, [0/560, 94%], loss is 0.163806\n",
      "Training Epoch: 730, [70/560, 96%], loss is 0.298746\n",
      "Training Epoch: 730, [140/560, 99%], loss is 0.387714\n",
      "Training Epoch: 730, [210/560, 94%], loss is 0.485123\n",
      "Training Epoch: 730, [280/560, 94%], loss is 0.621373\n",
      "Training Epoch: 730, [350/560, 94%], loss is 0.784428\n",
      "Training Epoch: 730, [420/560, 97%], loss is 0.890077\n",
      "Training Epoch: 730, [490/560, 93%], loss is 1.069657\n",
      "Training Epoch: 735, [0/560, 87%], loss is 0.354072\n",
      "Training Epoch: 735, [70/560, 91%], loss is 0.577936\n",
      "Training Epoch: 735, [140/560, 96%], loss is 0.681893\n",
      "Training Epoch: 735, [210/560, 94%], loss is 0.819841\n",
      "Training Epoch: 735, [280/560, 91%], loss is 1.042587\n",
      "Training Epoch: 735, [350/560, 93%], loss is 1.231875\n",
      "Training Epoch: 735, [420/560, 90%], loss is 1.613643\n",
      "Training Epoch: 735, [490/560, 90%], loss is 1.842343\n",
      "Training Epoch: 740, [0/560, 93%], loss is 0.204505\n",
      "Training Epoch: 740, [70/560, 96%], loss is 0.404040\n",
      "Training Epoch: 740, [140/560, 87%], loss is 0.703394\n",
      "Training Epoch: 740, [210/560, 90%], loss is 0.942059\n",
      "Training Epoch: 740, [280/560, 90%], loss is 1.125417\n",
      "Training Epoch: 740, [350/560, 93%], loss is 1.263117\n",
      "Training Epoch: 740, [420/560, 90%], loss is 1.435124\n",
      "Training Epoch: 740, [490/560, 90%], loss is 1.725876\n",
      "Training Epoch: 745, [0/560, 87%], loss is 0.462258\n",
      "Training Epoch: 745, [70/560, 81%], loss is 0.941536\n",
      "Training Epoch: 745, [140/560, 87%], loss is 1.159223\n",
      "Training Epoch: 745, [210/560, 89%], loss is 1.473431\n",
      "Training Epoch: 745, [280/560, 83%], loss is 1.855795\n",
      "Training Epoch: 745, [350/560, 89%], loss is 2.230196\n",
      "Training Epoch: 745, [420/560, 89%], loss is 2.649755\n",
      "Training Epoch: 745, [490/560, 93%], loss is 2.850915\n",
      "Training Epoch: 750, [0/560, 93%], loss is 0.259671\n",
      "Training Epoch: 750, [70/560, 96%], loss is 0.395745\n",
      "Training Epoch: 750, [140/560, 94%], loss is 0.576948\n",
      "Training Epoch: 750, [210/560, 94%], loss is 0.765358\n",
      "Training Epoch: 750, [280/560, 93%], loss is 0.937360\n",
      "Training Epoch: 750, [350/560, 93%], loss is 1.107887\n",
      "Training Epoch: 750, [420/560, 94%], loss is 1.252362\n",
      "Training Epoch: 750, [490/560, 90%], loss is 1.598895\n",
      "Training Epoch: 755, [0/560, 91%], loss is 0.241742\n",
      "Training Epoch: 755, [70/560, 96%], loss is 0.430023\n",
      "Training Epoch: 755, [140/560, 87%], loss is 0.736144\n",
      "Training Epoch: 755, [210/560, 90%], loss is 0.917936\n",
      "Training Epoch: 755, [280/560, 94%], loss is 1.105231\n",
      "Training Epoch: 755, [350/560, 96%], loss is 1.235926\n",
      "Training Epoch: 755, [420/560, 93%], loss is 1.445386\n",
      "Training Epoch: 755, [490/560, 94%], loss is 1.639266\n",
      "Training Epoch: 760, [0/560, 93%], loss is 0.237313\n",
      "Training Epoch: 760, [70/560, 96%], loss is 0.359536\n",
      "Training Epoch: 760, [140/560, 96%], loss is 0.540061\n",
      "Training Epoch: 760, [210/560, 91%], loss is 0.681985\n",
      "Training Epoch: 760, [280/560, 96%], loss is 0.822224\n",
      "Training Epoch: 760, [350/560, 89%], loss is 1.058525\n",
      "Training Epoch: 760, [420/560, 93%], loss is 1.234868\n",
      "Training Epoch: 760, [490/560, 97%], loss is 1.351697\n",
      "Training Epoch: 765, [0/560, 90%], loss is 0.267929\n",
      "Training Epoch: 765, [70/560, 96%], loss is 0.460839\n",
      "Training Epoch: 765, [140/560, 90%], loss is 0.638755\n",
      "Training Epoch: 765, [210/560, 91%], loss is 0.827814\n",
      "Training Epoch: 765, [280/560, 97%], loss is 1.019541\n",
      "Training Epoch: 765, [350/560, 91%], loss is 1.206531\n",
      "Training Epoch: 765, [420/560, 91%], loss is 1.539299\n",
      "Training Epoch: 765, [490/560, 96%], loss is 1.659301\n",
      "Training Epoch: 770, [0/560, 97%], loss is 0.089408\n",
      "Training Epoch: 770, [70/560, 96%], loss is 0.200723\n",
      "Training Epoch: 770, [140/560, 99%], loss is 0.293006\n",
      "Training Epoch: 770, [210/560, 93%], loss is 0.437593\n",
      "Training Epoch: 770, [280/560, 96%], loss is 0.532090\n",
      "Training Epoch: 770, [350/560, 97%], loss is 0.624076\n",
      "Training Epoch: 770, [420/560, 97%], loss is 0.772060\n",
      "Training Epoch: 770, [490/560, 97%], loss is 0.888880\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch: 775, [0/560, 97%], loss is 0.100024\n",
      "Training Epoch: 775, [70/560, 94%], loss is 0.256111\n",
      "Training Epoch: 775, [140/560, 97%], loss is 0.358287\n",
      "Training Epoch: 775, [210/560, 90%], loss is 0.508148\n",
      "Training Epoch: 775, [280/560, 97%], loss is 0.568484\n",
      "Training Epoch: 775, [350/560, 94%], loss is 0.747463\n",
      "Training Epoch: 775, [420/560, 99%], loss is 0.811011\n",
      "Training Epoch: 775, [490/560, 94%], loss is 0.977799\n",
      "Training Epoch: 780, [0/560, 94%], loss is 0.112678\n",
      "Training Epoch: 780, [70/560, 99%], loss is 0.204653\n",
      "Training Epoch: 780, [140/560, 94%], loss is 0.323031\n",
      "Training Epoch: 780, [210/560, 94%], loss is 0.416788\n",
      "Training Epoch: 780, [280/560, 94%], loss is 0.549755\n",
      "Training Epoch: 780, [350/560, 94%], loss is 0.746919\n",
      "Training Epoch: 780, [420/560, 91%], loss is 0.939085\n",
      "Training Epoch: 780, [490/560, 90%], loss is 1.215989\n",
      "Training Epoch: 785, [0/560, 93%], loss is 0.178856\n",
      "Training Epoch: 785, [70/560, 94%], loss is 0.330162\n",
      "Training Epoch: 785, [140/560, 96%], loss is 0.449090\n",
      "Training Epoch: 785, [210/560, 96%], loss is 0.554580\n",
      "Training Epoch: 785, [280/560, 96%], loss is 0.655169\n",
      "Training Epoch: 785, [350/560, 93%], loss is 0.877325\n",
      "Training Epoch: 785, [420/560, 96%], loss is 0.973492\n",
      "Training Epoch: 785, [490/560, 97%], loss is 1.055410\n",
      "Training Epoch: 790, [0/560, 90%], loss is 0.235527\n",
      "Training Epoch: 790, [70/560, 91%], loss is 0.449500\n",
      "Training Epoch: 790, [140/560, 91%], loss is 0.828014\n",
      "Training Epoch: 790, [210/560, 97%], loss is 0.941756\n",
      "Training Epoch: 790, [280/560, 93%], loss is 1.150151\n",
      "Training Epoch: 790, [350/560, 84%], loss is 1.584999\n",
      "Training Epoch: 790, [420/560, 89%], loss is 1.885879\n",
      "Training Epoch: 790, [490/560, 96%], loss is 2.121151\n",
      "Training Epoch: 795, [0/560, 93%], loss is 0.267466\n",
      "Training Epoch: 795, [70/560, 93%], loss is 0.431233\n",
      "Training Epoch: 795, [140/560, 94%], loss is 0.635484\n",
      "Training Epoch: 795, [210/560, 93%], loss is 0.815843\n",
      "Training Epoch: 795, [280/560, 93%], loss is 0.984720\n",
      "Training Epoch: 795, [350/560, 97%], loss is 1.058275\n",
      "Training Epoch: 795, [420/560, 86%], loss is 1.383722\n",
      "Training Epoch: 795, [490/560, 90%], loss is 1.621625\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    train_loss, train_best  = main(seed, dim_input, dim_hidden, up_limit, down_limit, batch_size, alpha, k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing_sigPQ_perturb_1\n",
      "Test set results: loss= 0.1126 accuracy= 96.2500 1-hop accuracy = 1.0000\n",
      "testing_sigPQ_perturb_1.5\n",
      "Test set results: loss= 0.4213 accuracy= 85.0000 1-hop accuracy = 0.9643\n",
      "testing_sigPQ_perturb_2\n",
      "Test set results: loss= 1.0435 accuracy= 74.4643 1-hop accuracy = 0.9089\n",
      "testing_sigPQ_perturb_3\n",
      "Test set results: loss= 2.5868 accuracy= 61.9643 1-hop accuracy = 0.8161\n",
      "[[96.25 85.   74.46 61.96]]\n"
     ]
    }
   ],
   "source": [
    "# Test the performance\n",
    "model_test = Net(dim_input, dim_hidden, nclass)\n",
    "model_test.load_state_dict(torch.load( os.path.join(model_dir,  savename + '.pt')))\n",
    "model_test.float()\n",
    "model_test.eval()\n",
    "acc_list = scenario_test(scenario, w, rootPath, model_test)\n",
    "print(acc_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
